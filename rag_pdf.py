import base64
import gradio as gr
import os
import shutil
import pymupdf as fitz  # PyMuPDF
import numpy as np
from PIL import Image
import io
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from pythainlp.tokenize import word_tokenize
from transformers import MT5Tokenizer, MT5ForConditionalGeneration

import torch
import ollama
import shortuuid
import logging
import re
import discord
import pandas as pd
import asyncio
import requests
from dotenv import load_dotenv
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from typing import List, Dict, Tuple, Union
import threading
import docx
from pathlib import Path
import json
import hashlib
from collections import deque
from datetime import datetime

# Load environment variables from .env file
load_dotenv()

# Image folder
TEMP_IMG="./data/images"
TEMP_VECTOR="./data/chromadb"
TEMP_VECTOR_BACKUP="./data/chromadb_backup"
# ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Model ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏ö‡∏ô Ollama
AVAILABLE_MODELS = ["gemma3:latest", "qwen3:latest","llama3.2:latest"]

# Discord Configuration
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "YOUR_WEBHOOK_URL_HERE")  # ‡πÉ‡∏™‡πà Webhook URL ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
DISCORD_BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN", "YOUR_BOT_TOKEN_HERE")  # ‡πÉ‡∏™‡πà Bot Token ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
DISCORD_CHANNEL_ID = os.getenv("DISCORD_CHANNEL_ID", "YOUR_CHANNEL_ID_HERE")  # ‡πÉ‡∏™‡πà Channel ID ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
DISCORD_ENABLED = os.getenv("DISCORD_ENABLED", "false").lower() == "true"  # ‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô Discord

# Discord Bot Configuration
DISCORD_BOT_ENABLED = os.getenv("DISCORD_BOT_ENABLED", "false").lower() == "true"  # ‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î Bot ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
DISCORD_BOT_PREFIX = os.getenv("DISCORD_BOT_PREFIX", "!ask ")  # ‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á
DISCORD_DEFAULT_MODEL = os.getenv("DISCORD_DEFAULT_MODEL", "gemma3:latest")  # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Discord
DISCORD_RESPOND_NO_PREFIX = os.getenv("DISCORD_RESPOND_NO_PREFIX", "true").lower() == "true"  # ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ prefix ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
DISCORD_REPLY_MODE = os.getenv("DISCORD_REPLY_MODE", "channel")  # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö: channel/dm/both

# LINE OA Configuration
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "YOUR_LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "YOUR_LINE_CHANNEL_SECRET")
LINE_ENABLED = os.getenv("LINE_ENABLED", "false").lower() == "true"  # ‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î LINE OA
LINE_DEFAULT_MODEL = os.getenv("LINE_DEFAULT_MODEL", "gemma3:latest")  # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LINE
LINE_WEBHOOK_PORT = int(os.getenv("LINE_WEBHOOK_PORT", "5000"))  # Port ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LINE webhook

# Facebook Messenger Configuration
FB_PAGE_ACCESS_TOKEN = os.getenv("FB_PAGE_ACCESS_TOKEN", "YOUR_FB_PAGE_ACCESS_TOKEN")
FB_VERIFY_TOKEN = os.getenv("FB_VERIFY_TOKEN", "YOUR_FB_VERIFY_TOKEN")
FB_ENABLED = os.getenv("FB_ENABLED", "false").lower() == "true"  # ‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î Facebook Messenger
FB_DEFAULT_MODEL = os.getenv("FB_DEFAULT_MODEL", "gemma3:latest")  # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FB
FB_WEBHOOK_PORT = int(os.getenv("FB_WEBHOOK_PORT", "5001"))  # Port ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FB webhook

# Enhanced RAG Configuration (MemoRAG-like features)
RAG_MODE = os.getenv("RAG_MODE", "enhanced")  # standard, enhanced
MEMORY_WINDOW_SIZE = int(os.getenv("MEMORY_WINDOW_SIZE", "5"))  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô conversations ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÑ‡∏ß‡πâ
ENABLE_CONTEXT_CHAINING = os.getenv("ENABLE_CONTEXT_CHAINING", "true").lower() == "true"
ENABLE_REASONING = os.getenv("ENABLE_REASONING", "true").lower() == "true"
ENABLE_SESSION_MEMORY = os.getenv("ENABLE_SESSION_MEMORY", "true").lower() == "true"

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# Initialize Chroma client Disable telemetry
os.environ["CHROMA_TELEMETRY_ENABLED"] = "false"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö database ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
os.makedirs(TEMP_VECTOR, exist_ok=True)
os.makedirs(TEMP_VECTOR_BACKUP, exist_ok=True)

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ChromaDB ‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏ñ‡∏≤‡∏ß‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
settings = Settings(
    anonymized_telemetry=False,
    allow_reset=False,
    is_persistent=True
)

chroma_client = chromadb.PersistentClient(
    path=TEMP_VECTOR,
    settings=settings
)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏∂‡∏á collection ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
try:
    # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÇ‡∏´‡∏•‡∏î collection ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô
    collection = chroma_client.get_collection(name="pdf_data")
    count = collection.count()
    logging.info(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î collection 'pdf_data' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {count} ‡πÄ‡∏£‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå‡∏î")
    logging.info(f"üìÅ Database path: {TEMP_VECTOR}")
    logging.info(f"üíæ Database exists: {os.path.exists(TEMP_VECTOR)}")
except Exception as e:
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
    logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö collection ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà - ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà: {str(e)}")
    collection = chroma_client.create_collection(name="pdf_data")
    logging.info(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á collection 'pdf_data' ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
logging.info(f"Using device: {device}")

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding
# SentenceTransformer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ (‡πÄ‡∏ô‡πâ‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)
sentence_model = SentenceTransformer('intfloat/multilingual-e5-base', device=device)

# Create directory for storing images
os.makedirs(TEMP_IMG, exist_ok=True)

sum_tokenizer = MT5Tokenizer.from_pretrained('StelleX/mt5-base-thaisum-text-summarization')
sum_model = MT5ForConditionalGeneration.from_pretrained('StelleX/mt5-base-thaisum-text-summarization')

def summarize_content(content: str) -> str:
    """
        ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ 
    """
    logging.info("%%%%%%%%%%%%%% SUMMARY %%%%%%%%%%%%%%%%%%%%%")    
       
    input_ = sum_tokenizer(content, truncation=True, max_length=1024, return_tensors="pt")
    with torch.no_grad():
        preds = sum_model.generate(
            input_['input_ids'].to('cpu'),
            num_beams=15,
            num_return_sequences=1,
            no_repeat_ngram_size=1,
            remove_invalid_values=True,
            max_length=250
        )

    summary = sum_tokenizer.decode(preds[0], skip_special_tokens=True)

    logging.info(f" summary: {summary}.")
    logging.info("%%%%%%%%%%%%%% SUMMARY %%%%%%%%%%%%%%%%%%%%%")
    return summary

# ‡πÅ‡∏¢‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤, ‡∏£‡∏π‡∏õ ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å PDF
def extract_pdf_content(pdf_path: str) -> List[Dict]:
    """
    ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å PDF ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ PyMuPDF
    """
    try:
        doc = fitz.open(pdf_path)
        content_chunks = []
        all_text=[]

        for page_num in range(len(doc)):
            page = doc[page_num]
            # Extract text
            text = page.get_text("text").strip()
            all_text.append(f"{text} \n\n\n")
            if not text:
                text = f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ {page_num + 1}"
            
            logging.info("################# Text data ##################")
            chunk_data = {"text": f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ {page_num + 1} : {text}" , "images": []}
            
            # Extract images
            image_list = page.get_images(full=True)
            logging.info("################# images list ##################")
            for img_index, img in enumerate(image_list):
                xref = img[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image["image"]
                image_ext = base_image["ext"]
                
                # Convert to PIL Image
                try:
                    image = Image.open(io.BytesIO(image_bytes))
                    if image.mode != "RGB":
                        image = image.convert("RGB")
                    
                    img_id = f"pic_{str(page_num+1)}_{str(img_index+1)}"
                    img_path = f"{TEMP_IMG}/{img_id}.{image_ext}"
                    image.save(img_path, format=image_ext.upper())

                    img_desc = f"‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ {str(page_num+1)} ‡∏Ç‡∏≠‡∏á ‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà {str(img_index+1)}, ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text[:80]}..."  
                    chunk_data["text"] += f"\n[‡∏†‡∏≤‡∏û: {img_id}.{image_ext}]"                    
                    chunk_data["images"].append({
                        "data": image,
                        "path": img_path,
                        "description": img_desc
                    })
                except Exception as e:
                    logger.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤ {str(page_num+1)}, ‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà {str(img_index+1)}: {str(e)}")
            
            if chunk_data["text"]:
                content_chunks.append(chunk_data)
        
        if not any(chunk["images"] for chunk in content_chunks):
            logger.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô PDF: %s", pdf_path)
        
        doc.close()
        content_text= "".join(all_text)
        # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        thaitoken_text = preprocess_thai_text(content_text) if any(ord(c) >= 0x0E00 and ord(c) <= 0x0E7F for c in text) else text
        print("################################")
        print(f"{ thaitoken_text }")
        print("################################")
        global summarize
        summarize = summarize_content(thaitoken_text)
        return content_chunks
    except Exception as e:
        logger.error("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å PDF: %s", str(e))
        raise

# ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ 
def preprocess_thai_text(text: str) -> str:
    """
    ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ pythainlp ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°

    Args:
        text (str): ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

    Returns:
        str: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÅ‡∏•‡πâ‡∏ß
    """
    return " ".join(word_tokenize(text, engine="newmm"))


def embed_text(text: str) -> np.ndarray:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ SentenceTransformer 

    Args:
        text (str): ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embedding        

    Returns:
        np.ndarray: Embedding vector ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
    """
    logging.info("-------------- start embed text  -------------------")
    
    # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    processed_text = preprocess_thai_text(text) if any(ord(c) >= 0x0E00 and ord(c) <= 0x0E7F for c in text) else text
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏î‡πâ‡∏ß‡∏¢ SentenceTransformer
    sentence_embedding = sentence_model.encode(processed_text, normalize_embeddings=True, device=device)    
        
    return sentence_embedding

def store_in_chroma(content_chunks: List[Dict], source_name: str):
    """
    ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô Chroma ‡∏û‡∏£‡πâ‡∏≠‡∏° embedding
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà (chunks with metadata) ‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤ (backward compatibility)
    """
    logging.info(f"##### Start store {len(content_chunks)} chunks in chroma #########")

    if not content_chunks:
        logging.warning("No chunks to store")
        return

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡πà‡∏≤
    if isinstance(content_chunks[0], dict) and "text" in content_chunks[0] and "metadata" in content_chunks[0]:
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà: chunks ‡∏û‡∏£‡πâ‡∏≠‡∏° metadata ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        store_chunks_modern(content_chunks)
    else:
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤: chunks ‡∏û‡∏£‡πâ‡∏≠‡∏° images (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ)
        store_chunks_legacy(content_chunks, source_name)


def store_chunks_modern(chunks: List[Dict]):
    """‡πÄ‡∏Å‡πá‡∏ö chunks ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ metadata ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
    logging.info("Storing chunks in modern format")

    for chunk in chunks:
        try:
            text = chunk["text"]
            chunk_metadata = chunk["metadata"]
            chunk_id = chunk["id"]

            logging.info(f"Processing chunk: {chunk_id} ({len(text)} chars)")

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
            text_embedding = embed_text(text)

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ChromaDB
            metadata = {
                "type": "text",
                "source": chunk_metadata.get("source", "unknown"),
                "file_type": chunk_metadata.get("file_type", "unknown"),
                "start": chunk_metadata.get("start", 0),
                "end": chunk_metadata.get("end", 0),
                "chunk_id": chunk_id
            }

            # ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô ChromaDB
            collection.add(
                documents=[text],
                metadatas=[metadata],
                embeddings=[text_embedding.tolist()],
                ids=[chunk_id]
            )

            logging.info(f"‚úÖ Stored chunk {chunk_id}")

        except Exception as e:
            logging.error(f"‚ùå Failed to store chunk {chunk.get('id', 'unknown')}: {str(e)}")


def store_chunks_legacy(chunks: List[Dict], source_name: str):
    """‡πÄ‡∏Å‡πá‡∏ö chunks ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤ (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö PDF ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°)"""
    logging.info("Storing chunks in legacy format")

    for chunk in chunks:
        try:
            text = chunk["text"]
            images = chunk.get("images", [])

            logging.info(f"Processing legacy chunk ({len(text)} chars)")

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
            text_embedding = embed_text(text)
            text_id = shortuuid.uuid()[:8]

            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            collection.add(
                documents=[text],
                metadatas=[{
                    "type": "text",
                    "source": source_name,
                    "format": "legacy"
                }],
                embeddings=[text_embedding.tolist()],
                ids=[text_id]
            )

            # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            for img in images:
                try:
                    img_id = shortuuid.uuid()[:8]
                    img_path = img.get("path", "")

                    collection.add(
                        documents=[text],
                        metadatas=[{
                            "type": "image",
                            "source": source_name,
                            "image_path": img_path,
                            "description": img.get("description", ""),
                            "format": "legacy"
                        }],
                        embeddings=[text_embedding.tolist()],
                        ids=[img_id]
                    )
                    logging.info(f"‚úÖ Stored image {img_id}")

                except Exception as e:
                    logging.error(f"‚ùå Failed to store image: {str(e)}")

        except Exception as e:
            logging.error(f"‚ùå Failed to store legacy chunk: {str(e)}")

def extract_text_from_file(file_path: str) -> str:
    """
    ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ (PDF, TXT, MD, DOCX)

    Args:
        file_path: ‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå

    Returns:
        str: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡πÑ‡∏î‡πâ
    """
    try:
        file_ext = Path(file_path).suffix.lower()

        if file_ext == '.pdf':
            return extract_pdf_text(file_path)
        elif file_ext in ['.txt', '.md']:
            return extract_text_file(file_path)
        elif file_ext == '.docx':
            return extract_docx_text(file_path)
        else:
            logging.warning(f"‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {file_ext}")
            return ""

    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å {file_path}: {str(e)}")
        return ""


def extract_pdf_text(pdf_path: str) -> str:
    """‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å PDF"""
    try:
        doc = fitz.open(pdf_path)
        text = ""
        for page_num in range(doc.page_count):
            page = doc[page_num]
            text += page.get_text()
        doc.close()
        return text
    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° PDF: {str(e)}")
        return ""


def extract_text_file(file_path: str) -> str:
    """‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .txt ‡∏´‡∏£‡∏∑‡∏≠ .md"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='cp1252') as f:
                return f.read()
        except Exception as e:
            logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {file_path}: {str(e)}")
            return ""
    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {file_path}: {str(e)}")
        return ""


def extract_docx_text(docx_path: str) -> str:
    """‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .docx"""
    try:
        doc = docx.Document(docx_path)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text
    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° DOCX: {str(e)}")
        return ""


def process_multiple_files(files, clear_before_upload: bool = False):
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå (PDF, TXT, MD, DOCX)

    Args:
        files: list ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Gradio
        clear_before_upload: ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    """
    try:
        if not files:
            return "‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î"

        current_count = collection.count()
        logging.info(f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {len(files)} ‡πÑ‡∏ü‡∏•‡πå")

        # ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á (Enhanced Backup)
        auto_backup_result = auto_backup_before_operation()
        if not auto_backup_result["success"]:
            logging.warning(f"Auto backup failed: {auto_backup_result.get('error')}")
        else:
            logging.info(f"Auto backup created: {auto_backup_result['backup_name']}")

        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
        if clear_before_upload:
            logging.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á...")
            clear_vector_db()

        total_chunks = 0
        successful_files = []
        failed_files = []

        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
        for file_obj in files:
            try:
                file_path = file_obj.name
                file_name = os.path.basename(file_path)
                file_ext = Path(file_path).suffix.lower()

                logging.info(f"#### ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå: {file_name} ({file_ext}) ####")

                # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå
                text_content = extract_text_from_file(file_path)

                if not text_content.strip():
                    failed_files.append(f"{file_name}: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ")
                    continue

                # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô chunks
                content_chunks = chunk_text(text_content, file_name)

                if not content_chunks:
                    failed_files.append(f"{file_name}: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ")
                    continue

                # ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô ChromaDB
                store_in_chroma(content_chunks, file_name)

                total_chunks += len(content_chunks)
                successful_files.append(file_name)

                logging.info(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {file_name} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - {len(content_chunks)} chunks")

            except Exception as e:
                error_msg = f"{file_name}: {str(e)}"
                failed_files.append(error_msg)
                logging.error(f"‚ùå ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {file_name} ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {str(e)}")

        # ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        backup_vector_db()

        new_count = collection.count()
        added_records = new_count - current_count

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        result = f"üéâ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\n\n"
        result += f"üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•:\n"
        result += f"‚Ä¢ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(files)} ‡πÑ‡∏ü‡∏•‡πå\n"
        result += f"‚Ä¢ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(successful_files)} ‡πÑ‡∏ü‡∏•‡πå\n"
        result += f"‚Ä¢ ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {len(failed_files)} ‡πÑ‡∏ü‡∏•‡πå\n"
        result += f"‚Ä¢ Chunks ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_chunks} ‡∏ä‡∏¥‡πâ‡∏ô\n"
        result += f"‚Ä¢ Records ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°: {added_records} ‡πÄ‡∏£‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå‡∏î\n"
        result += f"‚Ä¢ Records ‡∏£‡∏ß‡∏°: {new_count} ‡πÄ‡∏£‡∏Ñ‡∏Ñ‡∏≠‡∏£‡πå‡∏î\n\n"

        if successful_files:
            result += f"‚úÖ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:\n"
            for file_name in successful_files:
                result += f"  ‚Ä¢ {file_name}\n"
            result += "\n"

        if failed_files:
            result += f"‚ùå ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß:\n"
            for error in failed_files:
                result += f"  ‚Ä¢ {error}\n"
            result += "\n"

        result += f"üíæ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"

        return result

    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå: {str(e)}")
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"


# Google Sheets Integration
def extract_google_sheets_data(sheets_url: str) -> str:
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets

    Args:
        sheets_url: URL ‡∏Ç‡∏≠‡∏á Google Sheets

    Returns:
        ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡πâ‡∏ß
    """
    try:
        # ‡πÅ‡∏õ‡∏•‡∏á URL ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô export URL
        sheet_id = extract_sheet_id_from_url(sheets_url)
        if not sheet_id:
            return "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å Sheet ID ‡∏à‡∏≤‡∏Å URL ‡πÑ‡∏î‡πâ"

        # Export ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å‡πÄ‡∏õ‡πá‡∏ô CSV
        export_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid=0"

        # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame
        df = pd.read_csv(export_url)

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        text_content = format_dataframe_to_text(df, sheets_url)

        return text_content

    except Exception as e:
        logging.error(f"Error extracting Google Sheets data: {str(e)}")
        return f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets ‡πÑ‡∏î‡πâ: {str(e)}"


def extract_sheet_id_from_url(url: str) -> str:
    """
    ‡πÅ‡∏¢‡∏Å Sheet ID ‡∏à‡∏≤‡∏Å Google Sheets URL

    Args:
        url: Google Sheets URL

    Returns:
        Sheet ID
    """
    try:
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Google Sheets URL
        patterns = [
            r"/d/([a-zA-Z0-9-_]+)",
            r"id=([a-zA-Z0-9-_]+)"
        ]

        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)

        return ""
    except:
        return ""


def format_dataframe_to_text(df, source_url: str) -> str:
    """
    ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    """
    try:
        text_content = f"# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets\n"
        text_content += f"‡∏ó‡∏µ‡πà‡∏°‡∏≤: {source_url}\n"
        text_content += f"‡πÅ‡∏ñ‡∏ß: {len(df)}, ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {len(df.columns)}\n\n"

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        col_descriptions = []
        for i, col in enumerate(df.columns):
            col_descriptions.append(f"{col}")

        text_content += f"## ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°: {', '.join(col_descriptions)}\n\n"

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Q&A ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
        text_content += "## ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:\n\n"

        for index, row in df.iterrows():
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ô‡∏µ‡πâ
            row_content = []
            for col in df.columns:
                value = row[col]
                if pd.isna(value) or value == "":
                    continue

                # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡πà‡∏≤
                if isinstance(value, str) and len(value) > 100:
                    # ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏° "..."
                    value = value[:150] + "..." if len(value) > 150 else value

                row_content.append(f"{col}: {value}")

            if row_content:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
                text_content += f"### ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà {index + 1}:\n"
                text_content += f"{' '.join(row_content)}.\n\n"

                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Q&A ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
                if len(df.columns) >= 2:
                    # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
                    first_col = df.columns[0]
                    question_value = row[first_col]
                    if not pd.isna(question_value) and str(question_value).strip():
                        text_content += f"**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠:** {question_value}\n"

                        # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ
                        answers = []
                        for col in df.columns[1:]:
                            answer_value = row[col]
                            if not pd.isna(answer_value) and str(answer_value).strip():
                                answers.append(f"{answer_value}")

                        if answers:
                            text_content += f"**‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö/‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:** {' '.join(answers)}\n"

                        text_content += "\n"

        return text_content

    except Exception as e:
        logging.error(f"Error formatting DataFrame: {str(e)}")
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}"


def process_google_sheets_url(sheets_url: str, clear_before_upload: bool = False):
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Google Sheets URL

    Args:
        sheets_url: URL ‡∏Ç‡∏≠‡∏á Google Sheets
        clear_before_upload: ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    """
    try:
        logging.info(f"Starting to process Google Sheets: {sheets_url}")

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö URL
        if not sheets_url.strip():
            return "‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà Google Sheets URL"

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets
        text_content = extract_google_sheets_data(sheets_url)

        if text_content.startswith("‚ùå"):
            return text_content

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö source
        sheet_name = f"Google_Sheets_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô chunks
        chunks = chunk_text(text_content, sheet_name)

        # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        if clear_before_upload:
            clear_vector_db()
            logging.info("Cleared vector database before upload")

        # ‡πÄ‡∏Å‡πá‡∏ö chunks ‡∏•‡∏á‡πÉ‡∏ô ChromaDB
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡πà‡∏≤
        if chunks and isinstance(chunks[0], dict) and "text" in chunks[0] and "metadata" in chunks[0]:
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà: chunks ‡∏û‡∏£‡πâ‡∏≠‡∏° metadata ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
            store_chunks_modern(chunks)
        else:
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤: chunks ‡∏û‡∏£‡πâ‡∏≠‡∏° source name
            store_chunks_legacy(chunks, sheet_name)

        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ
        update_summary_data(chunks)

        result_msg = f"""‚úÖ ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
üìä URL: {sheets_url}
üìù ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö: {sheet_name}
üìÑ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks: {len(chunks)}
üìè ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(text_content):,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö RAG ‡πÅ‡∏•‡πâ‡∏ß!"""

        logging.info(f"Successfully processed Google Sheets: {sheet_name}")
        return result_msg

    except Exception as e:
        logging.error(f"Error processing Google Sheets URL: {str(e)}")
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Google Sheets: {str(e)}"


def chunk_text(text: str, source_file: str, chunk_size: int = 1000, overlap: int = 200) -> List[Dict]:
    """
    ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô chunks ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata

    Args:
        text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        source_file: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á
        chunk_size: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á chunk
        overlap: ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á chunks

    Returns:
        List[Dict]: list ‡∏Ç‡∏≠‡∏á chunks ‡∏û‡∏£‡πâ‡∏≠‡∏° metadata
    """
    if not text or len(text.strip()) < 50:
        return []

    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_size

        # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        if end < len(text):
            # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ß‡∏£‡∏£‡∏Ñ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
            for i in range(end, max(start, end - 100), -1):
                if text[i] in [' ', '\n', '.', '!', '?']:
                    end = i + 1
                    break

        chunk_text = text[start:end].strip()

        if len(chunk_text) > 50:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 50 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
            chunk_id = f"{source_file}_{start}_{end}"

            chunks.append({
                "text": chunk_text,
                "id": chunk_id,
                "metadata": {
                    "source": source_file,
                    "start": start,
                    "end": end,
                    "file_type": Path(source_file).suffix.lower()
                }
            })

        start = end - overlap if end - overlap > start else end

    return chunks


class EnhancedRAG:
    """
    Enhanced RAG System with MemoRAG-like features:
    - Memory management for conversations
    - Context chaining
    - Session-based reasoning
    - Cross-reference analysis
    """

    def __init__(self):
        self.session_memory = deque(maxlen=MEMORY_WINDOW_SIZE)
        self.session_context = []
        self.conversation_history = []
        self.current_session_id = self._generate_session_id()

    def _generate_session_id(self) -> str:
        """Generate unique session ID"""
        timestamp = datetime.now().isoformat()
        session_hash = hashlib.md5(timestamp.encode()).hexdigest()[:8]
        return f"session_{session_hash}"

    def add_to_memory(self, question: str, answer: str, contexts: List[str]):
        """Add conversation to memory"""
        memory_entry = {
            "session_id": self.current_session_id,
            "timestamp": datetime.now().isoformat(),
            "question": question,
            "answer": answer,
            "contexts": contexts[:3]  # Store top 3 contexts
        }
        self.session_memory.append(memory_entry)

        # Add to conversation history
        self.conversation_history.append({
            "role": "user",
            "content": question,
            "timestamp": memory_entry["timestamp"]
        })
        self.conversation_history.append({
            "role": "assistant",
            "content": answer,
            "timestamp": memory_entry["timestamp"]
        })

        logging.info(f"Added to memory: Session {self.current_session_id}")

    def get_relevant_memory(self, current_question: str) -> List[Dict]:
        """Get relevant memory entries based on current question"""
        if not ENABLE_SESSION_MEMORY:
            return []

        relevant_memories = []
        current_embedding = embed_text(current_question)

        for memory_entry in self.session_memory:
            # Calculate similarity between current question and memory
            memory_question = memory_entry["question"]
            memory_embedding = embed_text(memory_question)

            # Simple similarity check (can be improved with proper similarity calculation)
            similarity = np.dot(current_embedding, memory_embedding)

            if similarity > 0.7:  # Threshold for relevance
                relevant_memories.append({
                    "question": memory_entry["question"],
                    "answer": memory_entry["answer"],
                    "similarity": float(similarity),
                    "contexts": memory_entry["contexts"]
                })

        # Sort by similarity and return top results
        relevant_memories.sort(key=lambda x: x["similarity"], reverse=True)
        return relevant_memories[:3]  # Return top 3 relevant memories

    def build_context_prompt(self, question: str, contexts: List[str], relevant_memories: List[Dict],
                           show_source: bool = False, formal_style: bool = False) -> str:
        """Build enhanced prompt with memory and context chaining"""

        if not ENABLE_CONTEXT_CHAINING and not ENABLE_REASONING:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏ï‡∏≤‡∏°‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
            if formal_style:
                style_instruction = "‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"
                source_phrase = ""
                response_prefix = "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"
            else:
                style_instruction = "‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢"
                source_phrase = ""
                response_prefix = "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"

            source_instruction = ""
            if show_source:
                source_instruction = f"\n- ‡∏´‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ '{source_phrase}'" if source_phrase else "" if source_phrase else ""

            return f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å

**‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:**
- {style_instruction}
- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
- ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î
- ‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå{source_instruction}
- ‡∏≠‡∏≤‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:** {question}

**‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£:**
{summarize}

{context}

{response_prefix}"""

        # Enhanced prompt with memory and reasoning
        prompt_parts = []

        # Add context about memory if available
        if relevant_memories:
            prompt_parts.append("## ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (‡∏à‡∏≤‡∏Å Memory):")
            for i, memory in enumerate(relevant_memories, 1):
                prompt_parts.append(f"‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {i}:")
                prompt_parts.append(f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {memory['question']}")
                prompt_parts.append(f"‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {memory['answer'][:200]}...")
                prompt_parts.append("")

        # Add current contexts
        if contexts:
            prompt_parts.append("## ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£:")
            prompt_parts.extend(contexts)

        # Add reasoning prompt if enabled
        if ENABLE_REASONING:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏ï‡∏≤‡∏°‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
            if formal_style:
                style_instruction = "- ‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"
                source_phrase = ""
                response_prefix = "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"
            else:
                style_instruction = "- ‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢"
                source_phrase = ""
                response_prefix = "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"

            source_instruction = ""
            if show_source:
                source_instruction = f"\n- ‡∏´‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ '{source_phrase}'" if source_phrase else "" if source_phrase else ""

            prompt_parts.extend([
                "",
                "## ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:",
                style_instruction,
                "- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏à‡∏≥‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å",
                "- ‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå ‡πÇ‡∏î‡∏¢‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ",
                "- ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î",
                "- ‡∏≠‡∏≤‡∏à‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô" + source_instruction,
                "",
                "## ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:",
                "1. ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á",
                "2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ",
                "3. ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
                "4. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥"
            ])

        prompt_parts.extend([
            "",
            f"## ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {question}",
            "",
            f"## {response_prefix}:",
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
        ])

        return "\n".join(prompt_parts)

    def reset_session(self):
        """Reset current session"""
        self.current_session_id = self._generate_session_id()
        self.session_context = []
        self.conversation_history = []
        logging.info(f"Session reset: New session ID = {self.current_session_id}")

    def get_session_info(self) -> Dict:
        """Get current session information"""
        return {
            "session_id": self.current_session_id,
            "memory_size": len(self.session_memory),
            "conversation_length": len(self.conversation_history),
            "current_context_size": len(self.session_context)
        }


# Global Enhanced RAG instance
enhanced_rag = EnhancedRAG()


def process_pdf_upload(pdf_file):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ (deprecated - ‡πÉ‡∏ä‡πâ process_multiple_files ‡πÅ‡∏ó‡∏ô)
    """
    if pdf_file:
        return process_multiple_files([pdf_file], False)
    return "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå"

def clear_vector_db():
    try:
        
       # Clear existing collection to avoid duplicates
        chroma_client.delete_collection(name="pdf_data")
        global collection
        collection = chroma_client.create_collection(name="pdf_data")

    except Exception as e:
        return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}"
    
def update_summary_data(chunks: List[Dict]):
    """
    ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å chunks ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
    """
    try:
        global summarize

        # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å chunks
        total_chars = sum(len(chunk.get('text', '')) for chunk in chunks)
        source_files = set(chunk.get('metadata', {}).get('source', 'Unknown') for chunk in chunks)

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ
        summary_text = f"""üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î:
‚Ä¢ ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤: {', '.join(source_files)}
‚Ä¢ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks: {len(chunks)}
‚Ä¢ ‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ß‡∏°: {total_chars:,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
‚Ä¢ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

        summarize = summary_text
        logging.info(f"Updated summary data: {len(chunks)} chunks from {len(source_files)} sources")

    except Exception as e:
        logging.error(f"Error updating summary data: {str(e)}")
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        summarize = f"üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PDF: {len(chunks)} chunks, ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

def clear_vector_db_and_images():
    """
    ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Chroma vector database ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå images
    """
    
    try:
        clear_vector_db()
        
        pdf_input.clear()
        if os.path.exists(TEMP_IMG):
            shutil.rmtree(TEMP_IMG)
            os.makedirs(TEMP_IMG, exist_ok=True)
        
        return "‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô vector database ‡πÅ‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå images ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"
    except Exception as e:
        return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}"


async def send_to_discord(question: str, answer: str):
    """
    ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Discord channel
    """
    if not DISCORD_ENABLED or DISCORD_WEBHOOK_URL == "YOUR_WEBHOOK_URL_HERE":
        logging.info("Discord integration is disabled or not configured")
        return

    try:
        # ‡πÉ‡∏ä‡πâ Webhook URL ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
        webhook_url = DISCORD_WEBHOOK_URL

        embed = discord.Embed(
            title="üìö RAG PDF Bot - ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà",
            color=discord.Color.blue()
        )
        embed.add_field(name="‚ùì ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", value=question, inline=False)
        embed.add_field(name="üí¨ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö", value=answer[:1024] + "..." if len(answer) > 1024 else answer, inline=False)
        embed.set_footer(text="PDF RAG Assistant")

        # ‡πÉ‡∏ä‡πâ requests ‡πÅ‡∏ó‡∏ô discord client ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô event loop
        payload = {
            "embeds": [embed.to_dict()]
        }

        response = requests.post(webhook_url, json=payload, timeout=10)
        if response.status_code == 204:
            logging.info("‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á Discord ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        else:
            logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á Discord: {response.status_code} - {response.text}")

    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á Discord: {str(e)}")


def send_to_discord_sync(question: str, answer: str):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ discord ‡πÅ‡∏ö‡∏ö synchronous
    """
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á event loop ‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        if loop.is_running():
            # ‡∏ñ‡πâ‡∏≤ loop ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏ä‡πâ create_task
            asyncio.create_task(send_to_discord(question, answer))
        else:
            # ‡∏ñ‡πâ‡∏≤ loop ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡πÉ‡∏ä‡πâ run_until_complete
            loop.run_until_complete(send_to_discord(question, answer))
    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Discord: {str(e)}")


def backup_vector_db():
    """
    ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector database
    """
    try:
        if not os.path.exists(TEMP_VECTOR):
            logging.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå database ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            return False

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á timestamp ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö backup
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_folder = os.path.join(TEMP_VECTOR_BACKUP, f"backup_{timestamp}")

        # ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå backup
        shutil.copytree(TEMP_VECTOR, backup_folder)
        logging.info(f"‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {backup_folder}")

        # ‡∏•‡∏ö backup ‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤ 7 ‡∏ß‡∏±‡∏ô
        cleanup_old_backups()

        return True
    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {str(e)}")
        return False


def cleanup_old_backups(days_to_keep=7):
    """
    ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• backup ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    """
    try:
        now = datetime.now()

        for backup_name in os.listdir(TEMP_VECTOR_BACKUP):
            backup_path = os.path.join(TEMP_VECTOR_BACKUP, backup_name)
            if os.path.isdir(backup_path) and backup_name.startswith("backup_"):
                # ‡∏î‡∏∂‡∏á timestamp ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
                try:
                    timestamp_str = backup_name.replace("backup_", "")
                    backup_time = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")

                    # ‡∏•‡∏ö‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
                    if (now - backup_time).days > days_to_keep:
                        shutil.rmtree(backup_path)
                        logging.info(f"‡∏•‡∏ö backup ‡πÄ‡∏Å‡πà‡∏≤: {backup_name}")
                except ValueError:
                    continue
    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö backup ‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏î‡πâ: {str(e)}")


def backup_database_enhanced(backup_name=None, include_memory=False):
    """
    ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• database ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á
    """
    try:
        import json

        if backup_name is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"enhanced_backup_{timestamp}"

        backup_path = os.path.join(TEMP_VECTOR_BACKUP, backup_name)
        os.makedirs(backup_path, exist_ok=True)

        # Backup main database
        if os.path.exists(TEMP_VECTOR):
            backup_db_path = os.path.join(backup_path, "chromadb")
            shutil.copytree(TEMP_VECTOR, backup_db_path)
            logging.info(f"‡∏™‡∏≥‡∏£‡∏≠‡∏á ChromaDB: {backup_db_path}")

        # Backup Enhanced RAG memory if requested
        if include_memory and RAG_MODE == "enhanced":
            try:
                memory_info = enhanced_rag.get_memory_info()
                backup_memory_path = os.path.join(backup_path, "memory_info.json")

                with open(backup_memory_path, 'w', encoding='utf-8') as f:
                    json.dump(memory_info, f, ensure_ascii=False, indent=2)

                # Also backup memory collection if it exists
                if hasattr(enhanced_rag, 'memory_collection'):
                    memory_collection_backup = os.path.join(backup_path, "memory_collection")
                    os.makedirs(memory_collection_backup, exist_ok=True)

                    # Get all memories from collection
                    memories = enhanced_rag.memory_collection.get()
                    memory_json_path = os.path.join(memory_collection_backup, "memories.json")

                    with open(memory_json_path, 'w', encoding='utf-8') as f:
                        json.dump(memories, f, ensure_ascii=False, indent=2)

                logging.info("‡∏™‡∏≥‡∏£‡∏≠‡∏á Enhanced RAG Memory ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            except Exception as e:
                logging.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≥‡∏£‡∏≠‡∏á Memory: {str(e)}")

        # Create backup metadata
        metadata = {
            "backup_name": backup_name,
            "created_at": datetime.now().isoformat(),
            "type": "enhanced",
            "includes_memory": include_memory,
            "rag_mode": RAG_MODE,
            "database_info": get_database_info() if os.path.exists(TEMP_VECTOR) else None
        }

        metadata_path = os.path.join(backup_path, "backup_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        logging.info(f"‡∏™‡∏£‡πâ‡∏≤‡∏á Enhanced Backup ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {backup_path}")

        # Clean old backups
        cleanup_old_backups()

        return {
            "success": True,
            "backup_name": backup_name,
            "backup_path": backup_path,
            "metadata": metadata
        }

    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Enhanced Backup: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def restore_database_enhanced(backup_name=None):
    """
    ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô database ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á
    """
    try:
        import json

        if backup_name is None:
            # ‡∏´‡∏≤ backup ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
            backups = [d for d in os.listdir(TEMP_VECTOR_BACKUP)
                      if os.path.isdir(os.path.join(TEMP_VECTOR_BACKUP, d))]
            if not backups:
                return {"success": False, "error": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• backup"}
            backup_name = sorted(backups)[-1]

        backup_path = os.path.join(TEMP_VECTOR_BACKUP, backup_name)

        if not os.path.exists(backup_path):
            return {"success": False, "error": f"‡πÑ‡∏°‡πà‡∏û‡∏ö backup: {backup_name}"}

        # Validate backup integrity before restore
        is_valid, validation_message = validate_backup_integrity(backup_path)
        if not is_valid:
            logging.error(f"Backup validation failed: {validation_message}")
            return {"success": False, "error": f"Backup ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {validation_message}"}

        logging.info(f"Backup validation passed: {backup_name}")

        # Load backup metadata
        metadata_path = os.path.join(backup_path, "backup_metadata.json")
        metadata = {}
        if os.path.exists(metadata_path):
            try:
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                logging.info(f"Loaded backup metadata from: {metadata_path}")
            except json.JSONDecodeError as e:
                logging.warning(f"Invalid JSON in backup metadata: {str(e)}")
                metadata = {
                    "backup_name": backup_name,
                    "type": "unknown",
                    "includes_memory": False,
                    "rag_mode": "unknown"
                }
            except Exception as e:
                logging.warning(f"Could not read backup metadata: {str(e)}")
                metadata = {
                    "backup_name": backup_name,
                    "type": "unknown",
                    "includes_memory": False,
                    "rag_mode": "unknown"
                }

        # Create emergency backup of current data
        try:
            emergency_backup = backup_database_enhanced(
                f"emergency_restore_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )
            if not emergency_backup["success"]:
                logging.warning(f"Emergency backup failed: {emergency_backup.get('error')}")
                emergency_backup = {"success": False, "error": "Emergency backup failed"}
        except Exception as e:
            logging.error(f"Emergency backup creation failed: {str(e)}")
            emergency_backup = {"success": False, "error": str(e)}

        # Restore main database
        backup_db_path = os.path.join(backup_path, "chromadb")
        if os.path.exists(backup_db_path):
            if os.path.exists(TEMP_VECTOR):
                shutil.rmtree(TEMP_VECTOR)
            shutil.copytree(backup_db_path, TEMP_VECTOR)
            logging.info(f"‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô ChromaDB ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

        # Restore Enhanced RAG memory if available
        memory_collection_backup = os.path.join(backup_path, "memory_collection")
        if os.path.exists(memory_collection_backup) and RAG_MODE == "enhanced":
            try:
                memory_json_path = os.path.join(memory_collection_backup, "memories.json")
                if os.path.exists(memory_json_path):
                    try:
                        with open(memory_json_path, 'r', encoding='utf-8') as f:
                            memories = json.load(f)

                        # Validate memories structure
                        if all(key in memories for key in ['ids', 'documents', 'metadatas']):
                            # Clear current memory and restore from backup
                            if hasattr(enhanced_rag, 'memory_collection'):
                                enhanced_rag.memory_collection.delete()
                                enhanced_rag.memory_collection.add(
                                    ids=memories['ids'],
                                    documents=memories['documents'],
                                    metadatas=memories['metadatas']
                                )
                                logging.info("‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô Enhanced RAG Memory ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                        else:
                            logging.warning("Invalid memory backup structure - missing required keys")
                    except json.JSONDecodeError as e:
                        logging.warning(f"Invalid JSON in memory backup: {str(e)}")
                    except Exception as e:
                        logging.warning(f"Could not restore memory backup: {str(e)}")

            except Exception as e:
                logging.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô Memory: {str(e)}")

        # Reload collections
        global collection
        collection = chroma_client.get_or_create_collection(name="pdf_data")

        result = {
            "success": True,
            "backup_name": backup_name,
            "restored_at": datetime.now().isoformat(),
            "metadata": metadata,
            "emergency_backup": emergency_backup
        }

        logging.info(f"‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô Database ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏à‡∏≤‡∏Å: {backup_name}")
        return result

    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô Database: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def is_valid_backup_folder(backup_path):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏õ‡πá‡∏ô backup ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    """
    if not os.path.isdir(backup_path):
        return False

    # Check if it's a valid backup folder (has chromadb or backup_metadata.json)
    chromadb_path = os.path.join(backup_path, "chromadb")
    metadata_path = os.path.join(backup_path, "backup_metadata.json")

    return os.path.exists(chromadb_path) or os.path.exists(metadata_path)


def list_available_backups():
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ backup ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    """
    try:
        import json

        backups = []

        if not os.path.exists(TEMP_VECTOR_BACKUP):
            return backups

        for backup_name in sorted(os.listdir(TEMP_VECTOR_BACKUP), reverse=True):
            backup_path = os.path.join(TEMP_VECTOR_BACKUP, backup_name)

            # Only include valid backup folders
            if not is_valid_backup_folder(backup_path):
                continue

            # Try to load metadata
            metadata = {}
            metadata_path = os.path.join(backup_path, "backup_metadata.json")
            if os.path.exists(metadata_path):
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                except:
                    pass

            # Get backup size
            total_size = 0
            for root, dirs, files in os.walk(backup_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    if os.path.exists(file_path):
                        total_size += os.path.getsize(file_path)

            backup_info = {
                "name": backup_name,
                "path": backup_path,
                "size_mb": round(total_size / (1024 * 1024), 2),
                "created_at": metadata.get("created_at", "Unknown"),
                "type": metadata.get("type", "standard"),
                "includes_memory": metadata.get("includes_memory", False),
                "rag_mode": metadata.get("rag_mode", "unknown"),
                "database_info": metadata.get("database_info", {})
            }

            backups.append(backup_info)

        return backups

    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ backup: {str(e)}")
        return []


def delete_backup(backup_name):
    """
    ‡∏•‡∏ö backup ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏
    """
    try:
        backup_path = os.path.join(TEMP_VECTOR_BACKUP, backup_name)

        if not os.path.exists(backup_path):
            return {"success": False, "error": f"‡πÑ‡∏°‡πà‡∏û‡∏ö backup: {backup_name}"}

        if not os.path.isdir(backup_path):
            return {"success": False, "error": f"‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå backup: {backup_name}"}

        shutil.rmtree(backup_path)
        logging.info(f"‡∏•‡∏ö backup ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {backup_name}")

        return {"success": True, "message": f"‡∏•‡∏ö backup {backup_name} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"}

    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö backup: {str(e)}")
        return {"success": False, "error": str(e)}


def validate_backup_integrity(backup_path):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á backup
    """
    try:
        # Check main database
        chromadb_path = os.path.join(backup_path, "chromadb")
        if os.path.exists(chromadb_path):
            # Check if essential ChromaDB files exist
            sqlite_file = os.path.join(chromadb_path, "chroma.sqlite3")
            if not os.path.exists(sqlite_file):
                return False, "Missing chroma.sqlite3 file"

        # Check backup metadata JSON
        metadata_path = os.path.join(backup_path, "backup_metadata.json")
        if os.path.exists(metadata_path):
            try:
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    json.load(f)  # Try to parse JSON
            except json.JSONDecodeError:
                return False, "Invalid backup metadata JSON"

        # Check memory backup JSON if exists
        memory_collection_path = os.path.join(backup_path, "memory_collection")
        if os.path.exists(memory_collection_path):
            memory_json_path = os.path.join(memory_collection_path, "memories.json")
            if os.path.exists(memory_json_path):
                try:
                    with open(memory_json_path, 'r', encoding='utf-8') as f:
                        memories = json.load(f)
                        # Check if memory structure is valid
                        required_keys = ['ids', 'documents', 'metadatas']
                        if not all(key in memories for key in required_keys):
                            return False, "Invalid memory backup structure"
                except json.JSONDecodeError:
                    return False, "Invalid memory backup JSON"

        return True, "Backup is valid"

    except Exception as e:
        return False, f"Validation error: {str(e)}"


def cleanup_invalid_backups():
    """
    ‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà backup ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    """
    try:
        if not os.path.exists(TEMP_VECTOR_BACKUP):
            return

        cleaned_count = 0
        for folder_name in os.listdir(TEMP_VECTOR_BACKUP):
            folder_path = os.path.join(TEMP_VECTOR_BACKUP, folder_name)
            if os.path.isdir(folder_path):
                # Check if it's a valid backup folder
                if not is_valid_backup_folder(folder_path):
                    shutil.rmtree(folder_path)
                    cleaned_count += 1
                    logging.info(f"‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {folder_name}")
                else:
                    # Additional validation for backup integrity
                    is_valid, message = validate_backup_integrity(folder_path)
                    if not is_valid:
                        logging.warning(f"Backup {folder_name} failed validation: {message}")
                        # Don't delete automatically, just warn

        if cleaned_count > 0:
            logging.info(f"‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {cleaned_count} ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå")

    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ cleanup invalid backups: {str(e)}")


def auto_backup_before_operation():
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á backup ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    """
    try:
        # Clean invalid backups first
        cleanup_invalid_backups()

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"auto_backup_{timestamp}"

        result = backup_database_enhanced(
            backup_name=backup_name,
            include_memory=(RAG_MODE == "enhanced")
        )

        if result["success"]:
            logging.info(f"‡∏™‡∏£‡πâ‡∏≤‡∏á Auto Backup ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {backup_name}")
        else:
            logging.warning(f"‡∏™‡∏£‡πâ‡∏≤‡∏á Auto Backup ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('error')}")

        return result

    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Auto Backup: {str(e)}")
        return {"success": False, "error": str(e)}


def restore_vector_db(backup_name=None):
    """
    ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å backup

    Args:
        backup_name: ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå backup (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
    """
    try:
        if backup_name is None:
            # ‡∏´‡∏≤ backup ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
            backups = [d for d in os.listdir(TEMP_VECTOR_BACKUP)
                      if d.startswith("backup_") and os.path.isdir(os.path.join(TEMP_VECTOR_BACKUP, d))]
            if not backups:
                logging.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• backup")
                return False
            backup_name = sorted(backups)[-1]

        backup_path = os.path.join(TEMP_VECTOR_BACKUP, backup_name)

        if not os.path.exists(backup_path):
            logging.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö backup: {backup_name}")
            return False

        # ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô restore
        backup_vector_db()

        # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏à‡∏≤‡∏Å backup
        if os.path.exists(TEMP_VECTOR):
            shutil.rmtree(TEMP_VECTOR)

        shutil.copytree(backup_path, TEMP_VECTOR)
        logging.info(f"‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏à‡∏≤‡∏Å: {backup_name}")

        # ‡∏£‡∏µ‡πÇ‡∏´‡∏•‡∏î collection
        global collection
        collection = chroma_client.get_or_create_collection(name="pdf_data")

        return True
    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {str(e)}")
        return False


def get_database_info():
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ database ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    """
    try:
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        count = collection.count()

        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå
        db_exists = os.path.exists(TEMP_VECTOR)
        sqlite_exists = os.path.exists(os.path.join(TEMP_VECTOR, "chroma.sqlite3"))

        # ‡∏Ç‡∏ô‡∏≤‡∏î database
        db_size = 0
        if db_exists:
            for root, dirs, files in os.walk(TEMP_VECTOR):
                db_size += sum(os.path.getsize(os.path.join(root, name)) for name in files)

        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô backup
        backup_count = 0
        if os.path.exists(TEMP_VECTOR_BACKUP):
            backup_count = len([d for d in os.listdir(TEMP_VECTOR_BACKUP)
                               if d.startswith("backup_")])

        info = {
            "total_records": count,
            "database_path": TEMP_VECTOR,
            "database_exists": db_exists,
            "sqlite_exists": sqlite_exists,
            "database_size_mb": round(db_size / (1024 * 1024), 2),
            "backup_count": backup_count,
            "collections": list(chroma_client.list_collections())
        }

        logging.info(f"üìä Database Info: {count} records, {round(db_size/(1024*1024),2)}MB, {backup_count} backups")
        return info

    except Exception as e:
        logging.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• database ‡πÑ‡∏î‡πâ: {str(e)}")
        return {"error": str(e)}


def inspect_database():
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡πÉ‡∏ô database ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    """
    try:
        count = collection.count()
        if count == 0:
            return "Database ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ - ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3 records
        sample_data = collection.get(limit=3, include=["documents", "metadatas"])

        result = f"üìä Database Inspection:\n"
        result += f"üìù Total Records: {count}\n"
        result += f"üìÅ Collections: {list(chroma_client.list_collections())}\n\n"

        result += "üìã Sample Data (first 3 records):\n"
        for i, (doc, meta) in enumerate(zip(sample_data["documents"][:3], sample_data["metadatas"][:3])):
            result += f"\n{i+1}. Document: {doc[:100]}...\n"
            result += f"   Metadata: {meta}\n"
            result += f"   ---"

        return result

    except Exception as e:
        return f"‚ùå ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö database ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {str(e)}"


# Discord Bot for receiving questions
class RAGPDFBot(discord.Client):
    def __init__(self):
        intents = discord.Intents.default()
        intents.message_content = True  # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        super().__init__(intents=intents)
        self.is_ready = False

    async def on_ready(self):
        """‡πÄ‡∏°‡∏∑‡πà‡∏≠ Bot ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"""
        logging.info(f'Bot ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÄ‡∏õ‡πá‡∏ô {self.user}')
        self.is_ready = True
        # ‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á Bot
        await self.change_presence(
            activity=discord.Activity(
                type=discord.ActivityType.listening,
                name=f"{DISCORD_BOT_PREFIX}‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"
            )
        )

    async def on_message(self, message):
        """‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å Discord"""
        # ‡πÑ‡∏°‡πà‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á
        if message.author == self.user:
            return

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        should_respond = False
        question = ""
        response_type = ""

        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏°‡∏µ prefix (‡πÄ‡∏ä‡πà‡∏ô !ask)
        if message.content.startswith(DISCORD_BOT_PREFIX):
            question = message.content[len(DISCORD_BOT_PREFIX):].strip()
            should_respond = True
            response_type = "prefix"

        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏ñ‡∏π‡∏Å mention bot (‡πÄ‡∏ä‡πà‡∏ô @RAGPDFBot)
        elif self.user.mentioned_in(message):
            # ‡∏•‡∏ö mention ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            question = message.content.replace(f'<@!{self.user.id}>', '').replace(f'<@{self.user.id}>', '').strip()
            should_respond = True
            response_type = "mention"

        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà 3: ‡πÑ‡∏°‡πà‡∏°‡∏µ prefix ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        elif DISCORD_RESPOND_NO_PREFIX:
            question = message.content.strip()
            should_respond = True
            response_type = "auto"

        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö ‡πÉ‡∏´‡πâ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        if not should_respond or not question:
            return

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not question:
            if response_type == "prefix":
                await message.reply(
                    "‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n"
                    f"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: `{DISCORD_BOT_PREFIX}PDF ‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏∞‡πÑ‡∏£`"
                )
            elif response_type == "mention":
                await message.reply(
                    "‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å mention\n"
                    f"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: `@{self.user.name} PDF ‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏∞‡πÑ‡∏£`"
                )
            else:
                await message.reply(
                    "‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n"
                    f"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: `PDF ‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏∞‡πÑ‡∏£`"
                )
            return

        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        logging.info(f"Discord Bot: ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ({response_type}) - {question}")
        processing_msg = await message.reply("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö...")

        try:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ RAG system
            stream = query_rag(question, chat_llm=DISCORD_DEFAULT_MODEL)

            # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
            full_answer = ""
            for chunk in stream:
                content = chunk["message"]["content"]
                full_answer += content

            # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Discord)
            if len(full_answer) > 1990:  # Discord ‡∏à‡∏≥‡∏Å‡∏±‡∏î 2000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
                full_answer = full_answer[:1980] + "...\n\n*‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î*"

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embed ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
            embed = discord.Embed(
                title="",
                description=full_answer,
                color=discord.Color.blue()
            )

            # embed.add_field(name="‚ùì ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", value=question, inline=False)
            # embed.set_footer(text="PDF RAG Assistant ‚Ä¢ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å PDF ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
            # embed.set_thumbnail(url="https://cdn-icons-png.flaticon.com/512/2951/2951136.png")

            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            await processing_msg.delete()

            # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
            await respond_to_discord_message(message, embed, DISCORD_REPLY_MODE)

            logging.info(f"Discord Bot: ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ (‡πÇ‡∏´‡∏°‡∏î: {DISCORD_REPLY_MODE})")

        except Exception as e:
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            await processing_msg.delete()

            error_embed = discord.Embed(
                title="‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î",
                description=f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ: {str(e)}",
                color=discord.Color.red()
            )
            await respond_to_discord_message(message, error_embed, DISCORD_REPLY_MODE)
            logging.error(f"Discord Bot error: {str(e)}")


async def send_discord_dm(user, embed):
    """‡∏™‡πà‡∏á Direct Message ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ Discord"""
    try:
        await user.send(embed=embed)
        return True
    except discord.Forbidden:
        logging.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á DM ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ {user.name} ‡πÑ‡∏î‡πâ (‡∏≠‡∏≤‡∏à‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö DM)")
        return False
    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á DM: {str(e)}")
        return False


async def respond_to_discord_message(message, embed, reply_type="channel"):
    """‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô Discord ‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"""
    success_dm = False
    success_channel = False

    # ‡∏™‡πà‡∏á‡πÉ‡∏ô channel (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏´‡∏°‡∏î channel ‡∏´‡∏£‡∏∑‡∏≠ both)
    if reply_type in ["channel", "both"]:
        try:
            await message.reply(embed=embed)
            success_channel = True
        except Exception as e:
            logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô channel: {str(e)}")

    # ‡∏™‡πà‡∏á DM (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏´‡∏°‡∏î dm ‡∏´‡∏£‡∏∑‡∏≠ both)
    if reply_type in ["dm", "both"]:
        success_dm = await send_discord_dm(message.author, embed)

    # ‡∏ñ‡πâ‡∏≤‡∏™‡πà‡∏á DM ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏ï‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î dm ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡πÉ‡∏ô channel ‡πÅ‡∏ó‡∏ô
    if reply_type == "dm" and not success_dm:
        try:
            fallback_embed = discord.Embed(
                title="üì¨ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì",
                description=embed.description,
                color=embed.color
            )
            await message.reply(embed=fallback_embed)
            logging.info("‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô channel ‡πÅ‡∏ó‡∏ô ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á DM ‡πÑ‡∏î‡πâ")
        except Exception as e:
            logging.error(f"‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° fallback ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {str(e)}")


# Global variables for Discord Bot
discord_bot = None
discord_bot_thread = None


def start_discord_bot():
    """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô Discord Bot"""
    global discord_bot

    if not DISCORD_BOT_ENABLED or DISCORD_BOT_TOKEN == "YOUR_BOT_TOKEN_HERE":
        logging.info("Discord Bot ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
        return False

    try:
        discord_bot = RAGPDFBot()

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á event loop ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö bot
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ bot
        loop.run_until_complete(discord_bot.start(DISCORD_BOT_TOKEN))

    except Exception as e:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏° Discord Bot ‡πÑ‡∏î‡πâ: {str(e)}")
        return False


def start_discord_bot_thread():
    """‡πÄ‡∏£‡∏¥‡πà‡∏° Discord Bot ‡πÉ‡∏ô thread ‡πÅ‡∏¢‡∏Å"""
    global discord_bot_thread

    if discord_bot_thread and discord_bot_thread.is_alive():
        logging.warning("Discord Bot ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
        return False

    discord_bot_thread = threading.Thread(target=start_discord_bot, daemon=True)
    discord_bot_thread.start()

    # ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡πÉ‡∏´‡πâ bot ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    import time
    time.sleep(2)

    return True


def stop_discord_bot():
    """‡∏´‡∏¢‡∏∏‡∏î Discord Bot"""
    global discord_bot

    if discord_bot and discord_bot.is_ready:
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                loop.create_task(discord_bot.close())
            else:
                loop.run_until_complete(discord_bot.close())
            logging.info("Discord Bot ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß")
            return True
        except Exception as e:
            logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏¢‡∏∏‡∏î Discord Bot ‡πÑ‡∏î‡πâ: {str(e)}")
            return False

    return False


# Flask App for LINE OA and Facebook Messenger
app = Flask(__name__)

# LINE OA Setup
line_bot_api = None
line_handler = None
line_thread = None

# Facebook Messenger Setup
fb_thread = None


def setup_line_bot():
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ LINE Bot"""
    global line_bot_api, line_handler
    if LINE_ENABLED and LINE_CHANNEL_ACCESS_TOKEN != "YOUR_LINE_CHANNEL_ACCESS_TOKEN":
        try:
            line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
            line_handler = WebhookHandler(LINE_CHANNEL_SECRET)

            # Register handlers ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å setup ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
            register_line_handlers()

            logging.info("‚úÖ LINE Bot setup completed")
            return True
        except Exception as e:
            logging.error(f"‚ùå LINE Bot setup failed: {str(e)}")
            return False
    else:
        logging.info("LINE Bot is disabled or not configured")
        return False


def register_line_handlers():
    """Register LINE message handlers"""
    if line_handler:
        @line_handler.add(MessageEvent, message=TextMessage)
        def handle_line_message(event):
            """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å LINE"""
            try:
                user_message = event.message.text
                user_id = event.source.user_id

                logging.info(f"LINE Bot: ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å {user_id} - {user_message}")

                # ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
                line_bot_api.reply_message(
                    event.reply_token,
                    TextSendMessage(text="üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö...")
                )

                # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô background
                threading.Thread(
                    target=process_line_question,
                    args=(event, user_message, user_id)
                ).start()

            except Exception as e:
                logging.error(f"LINE Bot error: {str(e)}")
                try:
                    line_bot_api.reply_message(
                        event.reply_token,
                        TextSendMessage(text="‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà")
                    )
                except:
                    pass


def setup_facebook_bot():
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Facebook Messenger Bot"""
    if FB_ENABLED and FB_PAGE_ACCESS_TOKEN != "YOUR_FB_PAGE_ACCESS_TOKEN":
        logging.info("‚úÖ Facebook Messenger Bot setup completed")
        return True
    else:
        logging.info("Facebook Messenger Bot is disabled or not configured")
        return False


@app.route("/callback", methods=['POST'])
def line_callback():
    """LINE Webhook Callback"""
    if not LINE_ENABLED or not line_handler:
        abort(400)

    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)

    try:
        line_handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return 'OK'




def process_line_question(event, user_id: str, question: str):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å LINE"""
    try:
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        response = query_rag(question, LINE_DEFAULT_MODEL, show_source=False)
        answer = response.get('answer', '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö')

        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LINE (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 5000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
        if len(answer) > 4900:
            answer = answer[:4900] + "\n\n... (‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß)"

        # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE
        line_bot_api.push_message(
            user_id,
            TextSendMessage(text=answer)
        )

        logging.info(f"LINE Bot: ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

    except Exception as e:
        logging.error(f"LINE processing error: {str(e)}")
        try:
            line_bot_api.push_message(
                user_id,
                TextSendMessage(text="‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
            )
        except:
            pass


@app.route("/webhook", methods=['GET', 'POST'])
def facebook_webhook():
    """Facebook Messenger Webhook"""
    if not FB_ENABLED:
        abort(403)

    if request.method == 'GET':
        if request.args.get("hub.mode") == "subscribe" and request.args.get("hub.challenge"):
            if not request.args.get("hub.verify_token") == FB_VERIFY_TOKEN:
                return "Verification token mismatch", 403
            return request.args.get("hub.challenge"), 200
        return "Hello", 200

    elif request.method == 'POST':
        data = request.get_json()

        if data and "object" in data and data["object"] == "page":
            for entry in data["entry"]:
                for messaging_event in entry["messaging"]:
                    if messaging_event.get("message"):
                        sender_id = messaging_event["sender"]["id"]
                        message_text = messaging_event["message"].get("text")

                        if message_text:
                            # ‡πÉ‡∏ä‡πâ thread ‡πÅ‡∏¢‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
                            threading.Thread(
                                target=process_facebook_question,
                                args=(sender_id, message_text),
                                daemon=True
                            ).start()

        return "OK", 200


def process_facebook_question(sender_id: str, question: str):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å Facebook Messenger"""
    try:
        logging.info(f"Facebook Bot: ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å {sender_id} - {question}")

        # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        send_facebook_message(sender_id, "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì...")

        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        response = query_rag(question, FB_DEFAULT_MODEL, show_source=False)
        answer = response.get('answer', '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö')

        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Facebook (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 2000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
        if len(answer) > 1900:
            answer = answer[:1900] + "\n\n... (‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß)"

        # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Facebook
        send_facebook_message(sender_id, answer)

        logging.info(f"Facebook Bot: ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

    except Exception as e:
        logging.error(f"Facebook processing error: {str(e)}")
        try:
            send_facebook_message(sender_id, "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
        except:
            pass


def send_facebook_message(recipient_id: str, message_text: str):
    """‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á Facebook Messenger"""
    try:
        url = f"https://graph.facebook.com/v18.0/me/messages?access_token={FB_PAGE_ACCESS_TOKEN}"

        payload = {
            "recipient": {"id": recipient_id},
            "message": {"text": message_text}
        }

        response = requests.post(url, json=payload)
        response.raise_for_status()

    except Exception as e:
        logging.error(f"Error sending Facebook message: {str(e)}")


def start_line_server():
    """‡πÄ‡∏£‡∏¥‡πà‡∏° LINE Bot Server"""
    if setup_line_bot():
        try:
            app.run(host='0.0.0.0', port=LINE_WEBHOOK_PORT, debug=False)
        except Exception as e:
            logging.error(f"LINE server error: {str(e)}")


def start_facebook_server():
    """‡πÄ‡∏£‡∏¥‡πà‡∏° Facebook Bot Server"""
    if setup_facebook_bot():
        try:
            # Facebook ‡πÉ‡∏ä‡πâ port ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö LINE ‡∏ñ‡πâ‡∏≤ LINE ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
            port = FB_WEBHOOK_PORT if LINE_ENABLED else LINE_WEBHOOK_PORT
            app.run(host='0.0.0.0', port=port, debug=False)
        except Exception as e:
            logging.error(f"Facebook server error: {str(e)}")


def start_line_bot_thread():
    """‡πÄ‡∏£‡∏¥‡πà‡∏° LINE Bot ‡πÉ‡∏ô thread ‡πÅ‡∏¢‡∏Å"""
    global line_thread
    if line_thread and line_thread.is_alive():
        logging.warning("LINE Bot ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
        return False

    if not LINE_ENABLED:
        logging.info("LINE Bot is disabled")
        return False

    try:
        line_thread = threading.Thread(target=start_line_server, daemon=True)
        line_thread.start()
        logging.info(f"LINE Bot server started on port {LINE_WEBHOOK_PORT}")
        return True
    except Exception as e:
        logging.error(f"Failed to start LINE Bot: {str(e)}")
        return False


def start_facebook_bot_thread():
    """‡πÄ‡∏£‡∏¥‡πà‡∏° Facebook Bot ‡πÉ‡∏ô thread ‡πÅ‡∏¢‡∏Å"""
    global fb_thread
    if fb_thread and fb_thread.is_alive():
        logging.warning("Facebook Bot ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
        return False

    if not FB_ENABLED:
        logging.info("Facebook Bot is disabled")
        return False

    try:
        fb_thread = threading.Thread(target=start_facebook_server, daemon=True)
        fb_thread.start()
        logging.info(f"Facebook Bot server started on port {FB_WEBHOOK_PORT}")
        return True
    except Exception as e:
        logging.error(f"Failed to start Facebook Bot: {str(e)}")
        return False


def determine_optimal_results(question: str) -> int:
    """
    ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    """
    question_lower = question.lower()

    # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô - ‡πÉ‡∏ä‡πâ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
    comprehensive_keywords = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏¥‡πâ‡∏ô", "‡∏ó‡∏∏‡∏Å", "‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á", "‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏•‡∏¢"]
    if any(keyword in question_lower for keyword in comprehensive_keywords):
        return 8

    # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô - ‡πÉ‡∏ä‡πâ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
    counting_keywords = ["‡∏Å‡∏µ‡πà", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô", "‡∏°‡∏µ‡∏Å‡∏µ‡πà", "‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£", "‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á"]
    if any(keyword in question_lower for keyword in counting_keywords):
        return 5

    # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô - ‡πÉ‡∏ä‡πâ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
    selective_keywords = ["‡∏ö‡πâ‡∏≤‡∏á", "‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô", "‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á", "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", "‡∏Å‡∏£‡∏ì‡∏µ", "‡πÄ‡∏ä‡πà‡∏ô", "‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ"]
    if any(keyword in question_lower for keyword in selective_keywords):
        return 4

    # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á - ‡πÉ‡∏ä‡πâ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡πâ‡∏≠‡∏¢
    specific_keywords = ["‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà", "‡∏ó‡∏≥‡πÑ‡∏°", "‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£", "‡πÉ‡∏Ñ‡∏£"]
    if any(keyword in question_lower for keyword in specific_keywords):
        return 3

    # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ - ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    return 3


def calculate_relevance_score(question: str, context: str) -> float:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡∏∞ context (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)
    """
    # ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡∏∞ context
    question_words = set(word_tokenize(question))
    context_words = set(word_tokenize(context))

    if len(question_words) == 0:
        return 0.0

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
    common_words = question_words.intersection(context_words)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Jaccard similarity
    jaccard_similarity = len(common_words) / len(question_words.union(context_words))

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì keyword matching ‡πÅ‡∏ö‡∏ö case-insensitive
    question_lower = question.lower()
    context_lower = context.lower()

    # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
    exact_matches = 0
    partial_matches = 0

    for word in question_words:
        word_lower = word.lower()
        if word_lower in context_lower:
            exact_matches += 1

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ match ‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô "1-on-1" ‡∏Å‡∏±‡∏ö "session", "‡∏ô‡∏±‡∏î" ‡∏Å‡∏±‡∏ö "‡∏Ñ‡∏∏‡∏¢")
    for q_word in question_words:
        for c_word in context_words:
            # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡πÉ‡∏î‡∏Ñ‡∏≥‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏≥
            if q_word.lower() in c_word.lower() or c_word.lower() in q_word.lower():
                partial_matches += 0.5

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á semantically ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    semantic_matches = 0
    question_lower = question_lower.replace("1-on-1", "session ‡∏™‡∏≠‡∏ô‡πÄ‡∏™‡∏£‡∏¥‡∏° ‡∏ô‡∏±‡∏î‡∏Ñ‡∏∏‡∏¢")
    question_lower = question_lower.replace("‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á", "‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î")
    question_lower = question_lower.replace("‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢", "‡∏™‡∏≠‡∏ô‡πÄ‡∏™‡∏£‡∏¥‡∏°")
    question_lower = question_lower.replace("‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à", "‡∏Ç‡πâ‡∏≠‡∏™‡∏á‡∏™‡∏±‡∏¢")

    for word in question_lower.split():
        if word in context_lower and len(word) > 2:  # ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 2 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
            semantic_matches += 0.3

    # ‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏ö‡∏ö‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
    base_score = jaccard_similarity * 0.4
    exact_score = (exact_matches / len(question_words)) * 0.4
    partial_score = min(partial_matches / len(question_words), 0.3) * 0.2
    semantic_score = min(semantic_matches / len(question_words), 0.2) * 0.2

    final_score = base_score + exact_score + partial_score + semantic_score

    return min(final_score, 1.0)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà 1.0


def filter_relevant_contexts(question: str, documents: list, metadatas: list, min_relevance: float = 0.05) -> list:
    """
    ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ context ‡∏ó‡∏µ‡πàÁõ∏ÂÖ≥ÊÄß‡∏™‡∏π‡∏á
    """
    if not documents:
        return []

    filtered_contexts = []

    for doc, metadata in zip(documents, metadatas):
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        relevance_score = calculate_relevance_score(question, doc)

        # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ context ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô threshold
        if relevance_score >= min_relevance:
            filtered_contexts.append({
                'text': doc,
                'metadata': metadata,
                'relevance_score': relevance_score
            })

    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô)
    filtered_contexts.sort(key=lambda x: x['relevance_score'], reverse=True)

    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô context ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    max_contexts = 5
    return filtered_contexts[:max_contexts]


def query_rag(question: str, chat_llm: str = "gemma3:latest", show_source: bool = False, formal_style: bool = False):
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö Enhanced RAG ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö streaming ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Ollama
    """
    global summarize, enhanced_rag

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á
    if 'summarize' not in globals() or summarize is None:
        summarize = "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å PDF"

    logging.info(f"#### Enhanced RAG Mode: {RAG_MODE} #### ")
    logging.info(f"#### Question: {question} #### ")

    # Get relevant memories if enhanced mode is enabled
    relevant_memories = []
    if RAG_MODE == "enhanced":
        relevant_memories = enhanced_rag.get_relevant_memory(question)
        logging.info(f"Found {len(relevant_memories)} relevant memories")

    question_embedding = embed_text(question)

    # Smart Retrieval: ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    max_result = determine_optimal_results(question)
    logging.info(f"Using max_result: {max_result}")

    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ similarity threshold ‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
    results = collection.query(
        query_embeddings=[question_embedding.tolist()],
        n_results=max_result
    )

    # Relevance Filtering: ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ context ‡∏ó‡∏µ‡πàÁõ∏ÂÖ≥ÊÄß‡∏™‡∏π‡∏á
    filtered_contexts = filter_relevant_contexts(question, results["documents"][0], results["metadatas"][0], min_relevance=0.05)
    logging.info(f"Filtered {len(results['documents'][0])} contexts to {len(filtered_contexts)} relevant contexts")

    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ context ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    if len(filtered_contexts) == 0:
        logging.warning("No contexts passed relevance filter, using all retrieved contexts")
        filtered_contexts = [{'text': doc, 'metadata': meta} for doc, meta in zip(results["documents"][0], results["metadatas"][0])]

    context_texts = []
    image_paths = []

    # ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ context ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á
    for doc, metadata in zip([ctx['text'] for ctx in filtered_contexts], [ctx['metadata'] for ctx in filtered_contexts]):
        context_texts.append(doc)
        logging.info(f"Selected context: {doc}")
        logging.info(f"metadata: {metadata}")

        # Regex pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ [img: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå.jpeg]
        pattern = r"pic_(\d+)_(\d+)\.jpeg"
        imgs = re.findall(pattern, doc)

        if imgs:
            image_paths.append(imgs)
            logging.info(f"img: {imgs}")

        if metadata and metadata["type"] == "image":
            logging.info(f"image_path : { metadata['image_path']}")
            image_paths.append(metadata['image_path'])
    


    context = "\n".join(context_texts)

    # Build enhanced prompt using EnhancedRAG
    if RAG_MODE == "enhanced":
        prompt = enhanced_rag.build_context_prompt(question, context_texts, relevant_memories, show_source, formal_style)
        logging.info(f"Using Enhanced RAG prompt with {len(relevant_memories)} memories")
        logging.info("############## Begin Enhanced RAG Prompt #################")
        logging.info(f"prompt: {prompt}")
        logging.info("############## End Enhanced RAG Prompt #################")
    else:
        # Standard RAG prompt with stricter instructions
        if summarize is None:
            summarize = ""

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏ï‡∏≤‡∏°‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    if formal_style:
        style_instruction = "‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"
        source_phrase = ""
        response_prefix = "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"
    else:
        style_instruction = "‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢"
        source_phrase = ""
        response_prefix = "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"

    source_instruction = ""
    if show_source:
        source_instruction = f"\n- ‡∏´‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ '{source_phrase}'" if source_phrase else ""

    prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å

**‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:**
- {style_instruction}
- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
- ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î
- ‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå{source_instruction}
- ‡∏≠‡∏≤‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:** {question}

**‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£:**
{summarize}

{context}

{response_prefix}"""

    logging.info("############## Begin Standard Prompt #################")
    logging.info(f"prompt: {prompt}")
    logging.info("############## End Standard Prompt #################")
    logging.info(f"Prompt length: {len(prompt)} characters")

    logging.info("+++++++++++++  Send prompt To LLM  ++++++++++++++++++")
    ## Generation  ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö chat
    stream = ollama.chat(
        model=chat_llm,
        messages=[{"role": "user", "content": prompt}],      
        stream=True
    )
    
    return stream

# UI Event Handlers
def handle_file_selection(files):
    """
    Handle file selection with improved file list display
    """
    if not files:
        return gr.update(value=""), gr.update(visible=False)

    # Prepare file information
    file_info_list = []
    for file in files:
        file_path = file.name if hasattr(file, 'name') else str(file)
        file_name = os.path.basename(file_path)
        file_ext = os.path.splitext(file_name)[1].lower()

        # Determine file type
        if file_ext == '.pdf':
            file_type = 'üìÑ PDF'
        elif file_ext in ['.txt', '.md']:
            file_type = 'üìù Text'
        elif file_ext in ['.docx', '.doc']:
            file_type = 'üìã Word'
        else:
            file_type = 'üìÅ File'

        # Get file size
        try:
            if hasattr(file, 'size'):
                file_size = file.size
            elif os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
            else:
                file_size = 0

            # Format file size
            if file_size < 1024:
                size_str = f"{file_size} B"
            elif file_size < 1024 * 1024:
                size_str = f"{file_size / 1024:.1f} KB"
            else:
                size_str = f"{file_size / (1024 * 1024):.1f} MB"
        except:
            size_str = "Unknown"

        file_info_list.append({
            "name": file_name,
            "type": file_type,
            "size": size_str,
            "path": file_path
        })

    # Format file list display
    file_list_text = "## üìã Selected Files\n\n"
    for i, info in enumerate(file_info_list, 1):
        file_list_text += f"**{i}. {info['type']} {info['name']}**\n"
        file_list_text += f"   üìè Size: {info['size']}\n"
        file_list_text += f"   üìç Path: `{info['path']}`\n\n"

    return file_list_text, gr.update(visible=True)

def user(user_message: str, history: List[Dict]) -> Tuple[str, List[Dict]]:
    """
    ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ input ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏ó
    """
    return "", history + [{"role": "user", "content": user_message}]

def chatbot_interface(history: List[Dict], llm_model: str, show_source: bool = False, formal_style: bool = False,
                       send_to_discord: bool = False, send_to_line: bool = False, send_to_facebook: bool = False,
                       line_user_id: str = "", fb_user_id: str = ""):
    """
    ‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡πÅ‡∏ö‡∏ö streaming
    """
    user_message = history[-1]["content"]

    stream= query_rag(user_message, chat_llm=llm_model, show_source=show_source, formal_style=formal_style)

    history.append({"role": "assistant", "content": ""})
    full_answer=""
    """
    ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    """
    for chunk in stream:
        content = chunk["message"]["content"]
        full_answer += content 
        history[-1]["content"] += content
        #logging.info(f"content: {content}")
        yield history
    

    """
    ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á ‡πÇ‡∏î‡∏¢‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô 
    """

    # ‡πÉ‡∏ä‡πâ regex ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô [‡∏†‡∏≤‡∏û: ...] 
    print(full_answer)
    pattern1 = r"\[(?:‡∏†‡∏≤‡∏û:\s*)?(pic_\w+[-_]?\w*\.(?:jpe?g|png))\]"
    pattern2 = r"(pic_\w+[-_]?\w*\.(?:jpe?g|png))"
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏∏‡∏Å‡∏£‡∏π‡∏õ ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
    
    print("----------PPPP------------")       
    image_list = re.findall(pattern1, full_answer)
    print(image_list)
    if (len(image_list)==0):
        image_list = re.findall(pattern2, full_answer)
    print("----------xxxx------------")  
    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
    image_list_uniq = list(dict.fromkeys(image_list))  
    if image_list_uniq:
        history[-1]["content"] += "\n\n‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:"
        yield history    
        # ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á 
        for img in image_list_uniq:
            img_path = f"{TEMP_IMG}/{img}"
            logger.info(f"img_path: {img_path}")      
            if os.path.exists(img_path):
                    image = Image.open(img_path)
                    buffered = io.BytesIO()
                    image.save(buffered, format="PNG")
                    image_response = f"{img} ![{img}](data:image/png;base64,{base64.b64encode(buffered.getvalue()).decode()})"
                    #‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Chat
                    history.append({"role": "assistant", "content": image_response })
                    yield history

    # Store conversation in memory for Enhanced RAG
    if RAG_MODE == "enhanced":
        try:
            enhanced_rag.store_memory(user_message, full_answer)
            logging.info("Stored conversation in Enhanced RAG memory")
        except Exception as e:
            logging.error(f"Failed to store in Enhanced RAG memory: {str(e)}")

    # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    try:
        # ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á Discord (‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)
        if send_to_discord and DISCORD_ENABLED:
            send_to_discord_sync(user_message, full_answer)
            logging.info("‚úÖ ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Discord ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

        # ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE OA (‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡∏°‡∏µ user_id)
        if send_to_line and LINE_ENABLED and line_user_id and line_bot_api:
            try:
                # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LINE
                line_answer = full_answer
                if len(line_answer) > 4900:
                    line_answer = line_answer[:4900] + "\n\n... (‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß)"

                line_bot_api.push_message(
                    line_user_id,
                    TextSendMessage(text=f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {user_message}\n\n‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\n{line_answer}")
                )
                logging.info("‚úÖ ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE OA ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            except Exception as e:
                logging.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE OA: {str(e)}")

        # ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á Facebook Messenger (‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡∏°‡∏µ user_id)
        if send_to_facebook and FB_ENABLED and fb_user_id:
            try:
                # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Facebook
                fb_answer = full_answer
                if len(fb_answer) > 1900:
                    fb_answer = fb_answer[:1900] + "\n\n... (‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß)"

                send_facebook_message(
                    fb_user_id,
                    f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {user_message}\n\n‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\n{fb_answer}"
                )
                logging.info("‚úÖ ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Facebook Messenger ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            except Exception as e:
                logging.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á Facebook Messenger: {str(e)}")

    except Exception as e:
        logging.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°: {str(e)}")



# Gradio interface

with gr.Blocks(
    css="""
    .upload-container {
        border: 2px dashed #e0e0e0;
        border-radius: 12px;
        padding: 20px;
        background: #fafafa;
        transition: all 0.3s ease;
    }
    .upload-container:hover {
        border-color: #4CAF50;
        background: #f5f5f5;
    }
    .drop-zone {
        min-height: 150px;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        background: white;
        border: 2px dashed #ccc;
        border-radius: 8px;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    .drop-zone:hover {
        border-color: #4CAF50;
        background: #f9f9f9;
    }
    .options-container {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 15px;
        border: 1px solid #e9ecef;
    }
    .checkbox-primary label {
        color: #495057;
        font-weight: 500;
    }
    .checkbox-secondary label {
        color: #6c757d;
        font-size: 0.9em;
    }
    .upload-button {
        background: linear-gradient(45deg, #4CAF50, #45a049);
        border: none;
        color: white;
        padding: 12px 24px;
        font-weight: 600;
        border-radius: 8px;
        transition: all 0.3s ease;
    }
    .upload-button:hover {
        background: linear-gradient(45deg, #45a049, #3d8b40);
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .status-output {
        background: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 6px;
        font-family: 'Courier New', monospace;
    }
    """
) as demo:
    logo="https://camo.githubusercontent.com/9433204b08afdc976c2e4f5a4ba0d81f8877b585cc11206e2969326d25c41657/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f6e61726f6e67736b6d6c2f68746d6c352d6c6561726e406c61746573742f6173736574732f696d67732f546c697665636f64654c6f676f2d3435302e77656270"
    gr.Markdown(f"""<h3 style='display: flex; align-items: center; gap: 15px; padding: 10px; margin: 0;'>
        <img alt='T-LIVE-CODE' src='{logo}' style='height: 100px;' >
        <span style='font-size: 1.5em;'>‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó PDF: RAG</span></h3>""")

    with gr.Tab("üìö ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"):
        gr.Markdown("""
        ### üìÅ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå **PDF, DOCX, TXT, MD** ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        """)

        # Create a more professional upload section with drag-and-drop
        with gr.Column():
            # Upload area with drag-and-drop support
            with gr.Group(elem_classes="upload-container"):
                files_input = gr.File(
                    label="‡∏•‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏≤‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå",
                    file_count="multiple",
                    file_types=[".pdf", ".txt", ".md", ".docx"],
                    height=150,
                    elem_classes="drop-zone",
                    show_label=True,
                    container=True,
                    scale=0.98
                )

            # File display area
            with gr.Row():
                with gr.Column(scale=3):
                    gr.Markdown("""
                    **üìã ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:**
                    - ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå
                    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö PDF, TXT, MD, DOCX
                    - ‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: 100MB ‡∏ï‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
                    """)

                    selected_files_info = gr.Textbox(
                        label="‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å",
                        value="‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå",
                        interactive=False,
                        lines=3,
                        max_lines=5
                    )

                with gr.Column(scale=2):
                    gr.Markdown("""
                    **üí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**
                    ‚Ä¢ ‡∏•‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏≤‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
                    ‚Ä¢ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° "Browse Files" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
                    ‚Ä¢ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
                    """)

        # Processing options with better styling
        with gr.Group(elem_classes="options-container"):
            with gr.Row():
                with gr.Column(scale=2):
                    clear_before_upload = gr.Checkbox(
                        label="üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î",
                        value=False,
                        info="‡∏à‡∏∞‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà",
                        elem_classes="checkbox-primary"
                    )

                with gr.Column(scale=2):
                    include_memory_checkbox = gr.Checkbox(
                        label="üß† ‡∏£‡∏ß‡∏° Enhanced RAG Memory",
                        value=(RAG_MODE == "enhanced"),
                        info="‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°",
                        elem_classes="checkbox-secondary"
                    )

            # Action buttons with better styling
            with gr.Row():
                upload_button = gr.Button(
                    "üì§ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î",
                    variant="primary",
                    size="lg",
                    elem_classes="upload-button"
                )
                clear_button = gr.Button(
                    "üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î",
                    variant="secondary",
                    size="lg"
                )

        # Status display
        with gr.Accordion("üìä ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•", open=True):
            upload_output = gr.Textbox(
                label="‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå",
                lines=5,
                interactive=False,
                elem_classes="status-output"
            )

        # Connect event handlers
        files_input.upload(
            fn=handle_file_selection,
            inputs=[files_input],
            outputs=[selected_files_info, upload_output]
        )

        files_input.clear(
            fn=lambda: ([], "‡∏•‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡πâ‡∏ß"),
            inputs=[],
            outputs=[selected_files_info]
        )

        upload_button.click(
            fn=process_multiple_files,
            inputs=[files_input, clear_before_upload],
            outputs=upload_output
        )

        clear_button.click(
            fn=clear_vector_db_and_images,
            inputs=None,
            outputs=upload_output,
            queue=False
        )
        upload_output = gr.Textbox(label="‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•", lines=3)
        upload_button.click(
            fn=process_multiple_files,
            inputs=[files_input, clear_before_upload],
            outputs=upload_output
        )
        clear_button.click(
            fn=clear_vector_db_and_images,
            inputs=None,
            outputs=upload_output,
            queue=False
        )

        # Google Sheets Import Section
        gr.Markdown("---")
        with gr.Row():
            gr.Markdown("### üìä ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets")

        with gr.Group(elem_classes="upload-container"):
            gr.Markdown("""
            **üîó ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**
            1. ‡πÄ‡∏õ‡∏¥‡∏î Google Sheets ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤
            2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô **"‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏ï‡πà‡∏≠‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏ö‡∏ô‡πÄ‡∏ß‡πá‡∏ö"** (Share > General access > Anyone with the link)
            3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å URL ‡∏°‡∏≤‡∏ß‡∏≤‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
            """)

            with gr.Row():
                sheets_url_input = gr.Textbox(
                    label="üîó Google Sheets URL",
                    placeholder="https://docs.google.com/spreadsheets/d/...",
                    info="‡∏ß‡∏≤‡∏á URL ‡∏Ç‡∏≠‡∏á Google Sheets ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤",
                    scale=3
                )
                sheets_clear_checkbox = gr.Checkbox(
                    label="‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤",
                    value=False,
                    info="‡∏ï‡∏¥‡πä‡∏Å‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà",
                    scale=1
                )

            with gr.Row():
                sheets_import_button = gr.Button(
                    "üìä ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Google Sheets",
                    variant="primary",
                    size="lg",
                    elem_classes="upload-button"
                )

            sheets_output = gr.Textbox(
                label="‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
                lines=6,
                interactive=False,
                elem_classes="status-output"
            )

        # Connect Google Sheets event handlers
        sheets_import_button.click(
            fn=process_google_sheets_url,
            inputs=[sheets_url_input, sheets_clear_checkbox],
            outputs=sheets_output
        )

        # ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Database
        with gr.Row():
            gr.Markdown("### üóÑÔ∏è ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Database")

        # Enhanced Backup & Restore Section
        with gr.Accordion("üíæ Enhanced Backup & Restore", open=True):
            with gr.Row():
                # Backup Controls
                with gr.Column(scale=1):
                    gr.Markdown("#### üì¶ ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

                    backup_name_input = gr.Textbox(
                        label="‡∏ä‡∏∑‡πà‡∏≠ Backup (‡∏ñ‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)",
                        placeholder="‡πÄ‡∏ä‡πà‡∏ô: my_backup_20241030",
                        interactive=True
                    )

                    include_memory_checkbox = gr.Checkbox(
                        label="‡∏£‡∏ß‡∏° Enhanced RAG Memory",
                        value=(RAG_MODE == "enhanced"),
                        info="‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢"
                    )

                    with gr.Row():
                        enhanced_backup_button = gr.Button("‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á", variant="primary")
                        quick_backup_button = gr.Button("‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏î‡πà‡∏ß‡∏ô", variant="secondary")

                # Restore Controls
                with gr.Column(scale=1):
                    gr.Markdown("#### üîÑ ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

                    backup_selector = gr.Dropdown(
                        label="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Backup ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô",
                        choices=[],
                        interactive=True,
                        info="‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π backup ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
                    )

                    with gr.Row():
                        restore_button = gr.Button("‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", variant="primary")
                        refresh_backups_button = gr.Button("üîÑ ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä", size="sm")

            # Backup Status and Results
            backup_status_output = gr.Textbox(
                label="‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏≠‡∏á/‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô",
                lines=3,
                interactive=False
            )

            # Backup List Section
            with gr.Accordion("üìã ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Backup ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", open=False):
                backup_list_output = gr.Textbox(
                    label="‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Backup",
                    lines=8,
                    interactive=False
                )

                with gr.Row():
                    delete_backup_button = gr.Button("‡∏•‡∏ö Backup ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", variant="stop", size="sm")
                    validate_backup_button = gr.Button("‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå", variant="secondary", size="sm")
                    clean_invalid_button = gr.Button("üßπ ‡∏•‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á", variant="secondary", size="sm")
                    refresh_list_button = gr.Button("‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", size="sm")

        # Quick Database Operations
        with gr.Accordion("‚ö° ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡πà‡∏ß‡∏ô", open=False):
            with gr.Row():
                db_info_button = gr.Button("‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Database", variant="secondary")
                inspect_button = gr.Button("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", variant="secondary")
                auto_backup_button = gr.Button("‡∏™‡∏£‡πâ‡∏≤‡∏á Auto Backup", variant="secondary")

            db_info_output = gr.Textbox(label="‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Database", lines=5, interactive=False)
            inspect_output = gr.Textbox(label="‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡πÉ‡∏ô Database", lines=10, interactive=False)

        # Event Handlers for Enhanced Backup & Restore
        def enhanced_backup_handler(backup_name, include_memory):
            if not backup_name.strip():
                backup_name = None
            result = backup_database_enhanced(backup_name, include_memory)
            if result["success"]:
                return f"""‚úÖ ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
‚Ä¢ ‡∏ä‡∏∑‡πà‡∏≠ Backup: {result['backup_name']}
‚Ä¢ ‡∏£‡∏ß‡∏° Memory: {'‚úÖ' if include_memory else '‚ùå'}
‚Ä¢ ‡∏Ç‡∏ô‡∏≤‡∏î: {result['metadata']}

‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ backup"""
            else:
                return f"‚ùå ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('error', 'Unknown error')}"

        def quick_backup_handler():
            result = backup_database_enhanced()
            if result["success"]:
                return f"‚úÖ ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πà‡∏ß‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result['backup_name']}"
            else:
                return f"‚ùå ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('error', 'Unknown error')}"

        def restore_handler(backup_name):
            if not backup_name:
                return "‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å backup ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô"

            result = restore_database_enhanced(backup_name)
            if result["success"]:
                emergency_name = result.get('emergency_backup', {}).get('backup_name', 'N/A')
                return f"""‚úÖ ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
‚Ä¢ ‡∏à‡∏≤‡∏Å Backup: {backup_name}
‚Ä¢ ‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô: {result['restored_at']}
‚Ä¢ ‡∏™‡∏£‡πâ‡∏≤‡∏á Emergency Backup: {emergency_name}

‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô"""
            else:
                return f"‚ùå ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('error', 'Unknown error')}"

        def refresh_backups_handler():
            backups = list_available_backups()
            if backups:
                choices = [backup["name"] for backup in backups]
                return gr.Dropdown(choices=choices, value=choices[0] if choices else None)
            else:
                return gr.Dropdown(choices=[], value=None)

        def get_backup_list_handler():
            backups = list_available_backups()
            if backups:
                backup_info = []
                for backup in backups:
                    info = f"""üìÅ {backup['name']}
‚Ä¢ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠: {backup['created_at']}
‚Ä¢ ‡∏Ç‡∏ô‡∏≤‡∏î: {backup['size_mb']} MB
‚Ä¢ ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {backup['type']}
‚Ä¢ Memory: {'‚úÖ' if backup['includes_memory'] else '‚ùå'}
‚Ä¢ RAG Mode: {backup['rag_mode']}
‚Ä¢ Records: {backup['database_info'].get('total_records', 'N/A') if backup['database_info'] else 'N/A'}
---"""
                    backup_info.append(info)
                return "\n".join(backup_info)
            else:
                return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• backup ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

        def delete_backup_handler(backup_name):
            if not backup_name:
                return "‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å backup ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏•‡∏ö"

            result = delete_backup(backup_name)
            if result["success"]:
                return f"‚úÖ {result['message']}"
            else:
                return f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö backup: {result.get('error', 'Unknown error')}"

        def auto_backup_handler():
            result = auto_backup_before_operation()
            if result["success"]:
                return f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Auto Backup ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result['backup_name']}"
            else:
                return f"‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á Auto Backup ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('error', 'Unknown error')}"

        def clean_invalid_handler():
            try:
                cleanup_invalid_backups()
                return "‚úÖ ‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß"
            except Exception as e:
                return f"‚ùå ‡∏•‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {str(e)}"

        def validate_backup_handler(backup_name):
            if not backup_name:
                return "‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å backup ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö"

            backup_path = os.path.join(TEMP_VECTOR_BACKUP, backup_name)
            if not os.path.exists(backup_path):
                return f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö backup: {backup_name}"

            is_valid, message = validate_backup_integrity(backup_path)
            if is_valid:
                return f"""‚úÖ Backup ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á!
‚Ä¢ ‡∏ä‡∏∑‡πà‡∏≠ Backup: {backup_name}
‚Ä¢ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: {message}
‚Ä¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô"""
            else:
                return f"""‚ùå Backup ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á!
‚Ä¢ ‡∏ä‡∏∑‡πà‡∏≠ Backup: {backup_name}
‚Ä¢ ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {message}
‚Ä¢ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏™‡∏£‡πâ‡∏≤‡∏á backup ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ó‡∏ô"""

        # Connect event handlers
        enhanced_backup_button.click(
            fn=enhanced_backup_handler,
            inputs=[backup_name_input, include_memory_checkbox],
            outputs=backup_status_output,
            queue=False
        )

        quick_backup_button.click(
            fn=quick_backup_handler,
            inputs=None,
            outputs=backup_status_output,
            queue=False
        )

        restore_button.click(
            fn=restore_handler,
            inputs=backup_selector,
            outputs=backup_status_output,
            queue=False
        )

        refresh_backups_button.click(
            fn=refresh_backups_handler,
            inputs=None,
            outputs=backup_selector,
            queue=False
        )

        refresh_list_button.click(
            fn=get_backup_list_handler,
            inputs=None,
            outputs=backup_list_output,
            queue=False
        )

        delete_backup_button.click(
            fn=delete_backup_handler,
            inputs=backup_selector,
            outputs=backup_list_output,
            queue=False
        )

        auto_backup_button.click(
            fn=auto_backup_handler,
            inputs=None,
            outputs=db_info_output,
            queue=False
        )

        clean_invalid_button.click(
            fn=clean_invalid_handler,
            inputs=None,
            outputs=backup_status_output,
            queue=False
        )

        validate_backup_button.click(
            fn=validate_backup_handler,
            inputs=backup_selector,
            outputs=backup_status_output,
            queue=False
        )

        # Initialize backup list on page load
        demo.load(
            fn=refresh_backups_handler,
            inputs=None,
            outputs=backup_selector,
            queue=False
        )

        # Quick database operations handlers
        db_info_button.click(
            fn=lambda: str(get_database_info()),
            inputs=None,
            outputs=db_info_output,
            queue=False
        )

        inspect_button.click(
            fn=inspect_database,
            inputs=None,
            outputs=inspect_output,
            queue=False
        )

        # ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Discord Bot
        with gr.Row():
            gr.Markdown("### ü§ñ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Discord Bot")

        with gr.Row():
            start_bot_button = gr.Button("‡πÄ‡∏£‡∏¥‡πà‡∏° Discord Bot", variant="primary")
            stop_bot_button = gr.Button("‡∏´‡∏¢‡∏∏‡∏î Discord Bot", variant="stop")

        bot_status_output = gr.Textbox(label="‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Discord Bot", lines=3)

        with gr.Row():
            bot_model_selector = gr.Dropdown(
                choices=AVAILABLE_MODELS,
                value=DISCORD_DEFAULT_MODEL,
                label="‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Discord Bot"
            )

            bot_reply_mode = gr.Dropdown(
                choices=[
                    ("‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô Channel", "channel"),
                    ("‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô DM", "dm"),
                    ("‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á Channel ‡πÅ‡∏•‡∏∞ DM", "both")
                ],
                value=DISCORD_REPLY_MODE,
                label="‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö"
            )

        def update_discord_model(model):
            global DISCORD_DEFAULT_MODEL
            DISCORD_DEFAULT_MODEL = model
            return f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏• Discord Bot ‡πÄ‡∏õ‡πá‡∏ô {model}"

        def update_discord_reply_mode(mode):
            global DISCORD_REPLY_MODE
            DISCORD_REPLY_MODE = mode
            mode_name = {"channel": "‡πÉ‡∏ô Channel", "dm": "‡πÉ‡∏ô DM", "both": "‡∏ó‡∏±‡πâ‡∏á Channel ‡πÅ‡∏•‡∏∞ DM"}
            return f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô: {mode_name.get(mode, mode)}"

        def start_bot_ui():
            if start_discord_bot_thread():
                return "Discord Bot ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß! ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏î‡πâ‡πÉ‡∏ô Discord"
            else:
                return "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏° Discord Bot ‡πÑ‡∏î‡πâ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô .env"

        def stop_bot_ui():
            if stop_discord_bot():
                return "Discord Bot ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß"
            else:
                return "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏¢‡∏∏‡∏î Discord Bot ‡πÑ‡∏î‡πâ"

        start_bot_button.click(
            fn=start_bot_ui,
            inputs=None,
            outputs=bot_status_output,
            queue=False
        )

        stop_bot_button.click(
            fn=stop_bot_ui,
            inputs=None,
            outputs=bot_status_output,
            queue=False
        )

        bot_model_selector.change(
            fn=update_discord_model,
            inputs=bot_model_selector,
            outputs=bot_status_output,
            queue=False
        )

        bot_reply_mode.change(
            fn=update_discord_reply_mode,
            inputs=bot_reply_mode,
            outputs=bot_status_output,
            queue=False
        )

        # ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ LINE OA Bot
        with gr.Row():
            gr.Markdown("### üì± ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ LINE OA Bot")

        with gr.Row():
            start_line_button = gr.Button("‡πÄ‡∏£‡∏¥‡πà‡∏° LINE OA Bot", variant="primary")
            stop_line_button = gr.Button("‡∏´‡∏¢‡∏∏‡∏î LINE OA Bot", variant="stop")

        line_status_output = gr.Textbox(label="‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ LINE OA Bot", lines=3)
        line_model_selector = gr.Dropdown(
            choices=AVAILABLE_MODELS,
            value=LINE_DEFAULT_MODEL,
            label="‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LINE OA Bot"
        )

        def update_line_model(model):
            global LINE_DEFAULT_MODEL
            LINE_DEFAULT_MODEL = model
            return f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏• LINE OA Bot ‡πÄ‡∏õ‡πá‡∏ô {model}"

        def start_line_ui():
            if start_line_bot_thread():
                return f"LINE OA Bot ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß! Webhook URL: http://localhost:{LINE_WEBHOOK_PORT}/callback"
            else:
                return "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏° LINE OA Bot ‡πÑ‡∏î‡πâ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô .env"

        def stop_line_ui():
            if line_thread and line_thread.is_alive():
                return "LINE OA Bot ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß (‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ restart ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°)"
            else:
                return "LINE OA Bot ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß"

        start_line_button.click(
            fn=start_line_ui,
            inputs=None,
            outputs=line_status_output,
            queue=False
        )

        stop_line_button.click(
            fn=stop_line_ui,
            inputs=None,
            outputs=line_status_output,
            queue=False
        )

        line_model_selector.change(
            fn=update_line_model,
            inputs=line_model_selector,
            outputs=line_status_output,
            queue=False
        )

        # ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Facebook Messenger Bot
        with gr.Row():
            gr.Markdown("### üí¨ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Facebook Messenger Bot")

        with gr.Row():
            start_fb_button = gr.Button("‡πÄ‡∏£‡∏¥‡πà‡∏° Facebook Bot", variant="primary")
            stop_fb_button = gr.Button("‡∏´‡∏¢‡∏∏‡∏î Facebook Bot", variant="stop")

        fb_status_output = gr.Textbox(label="‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Facebook Bot", lines=3)
        fb_model_selector = gr.Dropdown(
            choices=AVAILABLE_MODELS,
            value=FB_DEFAULT_MODEL,
            label="‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Facebook Bot"
        )

        def update_fb_model(model):
            global FB_DEFAULT_MODEL
            FB_DEFAULT_MODEL = model
            return f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏• Facebook Bot ‡πÄ‡∏õ‡πá‡∏ô {model}"

        def start_fb_ui():
            if start_facebook_bot_thread():
                return f"Facebook Bot ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß! Webhook URL: http://localhost:{FB_WEBHOOK_PORT}/webhook"
            else:
                return "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏° Facebook Bot ‡πÑ‡∏î‡πâ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô .env"

        def stop_fb_ui():
            if fb_thread and fb_thread.is_alive():
                return "Facebook Bot ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß (‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ restart ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°)"
            else:
                return "Facebook Bot ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß"

        start_fb_button.click(
            fn=start_fb_ui,
            inputs=None,
            outputs=fb_status_output,
            queue=False
        )

        stop_fb_button.click(
            fn=stop_fb_ui,
            inputs=None,
            outputs=fb_status_output,
            queue=False
        )

        fb_model_selector.change(
            fn=update_fb_model,
            inputs=fb_model_selector,
            outputs=fb_status_output,
            queue=False
        )

    with gr.Tab("‡πÅ‡∏ä‡∏ó"):
        # Choice ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model
        model_selector = gr.Dropdown(
            choices=AVAILABLE_MODELS,
            value="gemma3:latest",
            label="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å LLM Model"
        )
        selected_model = gr.State(value="gemma3:latest")  # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô state
        model_selector.change(fn=lambda x: x, inputs=model_selector, outputs=selected_model)

        # Choice ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å RAG Mode
        rag_mode_selector = gr.Radio(
            choices=[
                ("üìñ Standard RAG - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô", "standard"),
                ("üß† Enhanced RAG - ‡∏à‡∏î‡∏à‡∏≥‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", "enhanced")
            ],
            value="standard",
            label="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î RAG",
            info="Enhanced RAG ‡∏à‡∏∞‡∏à‡∏î‡∏à‡∏≥‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"
        )
        selected_rag_mode = gr.State(value="standard")  # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô state
        rag_mode_status = gr.Textbox(label="‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ RAG Mode", value="üìñ Standard RAG Mode", interactive=False)

        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        with gr.Row():
            show_source_checkbox = gr.Checkbox(
                label="üîç ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
                value=False,
                info="‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö"
            )

            formal_style_checkbox = gr.Checkbox(
                label="üìù ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£",
                value=False,
                info="‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"
            )

        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏≠‡∏∑‡πà‡∏ô
        with gr.Row():
            gr.Markdown("### üì§ ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°:")

        with gr.Row():
            send_to_discord_checkbox = gr.Checkbox(
                label="ü§ñ Discord",
                value=False,
                info="‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Discord channel"
            )

            send_to_line_checkbox = gr.Checkbox(
                label="üì± LINE OA",
                value=False,
                info="‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE OA (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ LINE_USER_ID)"
            )

            send_to_facebook_checkbox = gr.Checkbox(
                label="üí¨ Facebook Messenger",
                value=False,
                info="‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Facebook Messenger (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ FB_USER_ID)"
            )

        # ‡πÄ‡∏û‡∏¥‡πà‡∏° text input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏∏ user ID
        with gr.Row():
            line_user_id_input = gr.Textbox(
                label="LINE User ID (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)",
                placeholder="‡πÉ‡∏™‡πà LINE User ID ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö",
                visible=False,
                info="‡∏£‡∏±‡∏ö User ID ‡∏à‡∏≤‡∏Å LINE Debug console ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö"
            )

            fb_user_id_input = gr.Textbox(
                label="Facebook User ID (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)",
                placeholder="‡πÉ‡∏™‡πà Facebook User ID ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö",
                visible=False,
                info="‡∏£‡∏±‡∏ö User ID ‡∏à‡∏≤‡∏Å Facebook Graph API"
            )

        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á/‡∏ã‡πà‡∏≠‡∏ô user ID input
        def toggle_line_input(checked):
            return gr.update(visible=checked)

        def toggle_fb_input(checked):
            return gr.update(visible=checked)

        send_to_line_checkbox.change(
            fn=toggle_line_input,
            inputs=send_to_line_checkbox,
            outputs=line_user_id_input
        )

        send_to_facebook_checkbox.change(
            fn=toggle_fb_input,
            inputs=send_to_facebook_checkbox,
            outputs=fb_user_id_input
        )

        def update_rag_mode(mode):
            global RAG_MODE
            RAG_MODE = mode
            if mode == "enhanced":
                return "üß† Enhanced RAG Mode - ‡∏à‡∏∞‡∏à‡∏î‡∏à‡∏≥‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"
            else:
                return "üìñ Standard RAG Mode - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"

        rag_mode_selector.change(
            fn=update_rag_mode,
            inputs=rag_mode_selector,
            outputs=rag_mode_status,
            queue=False
        )

        # Enhanced RAG Memory Status
        with gr.Accordion("üß† Enhanced RAG Memory Status", open=False):
            memory_status_output = gr.Textbox(label="‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Memory", lines=4, interactive=False)
            refresh_memory_button = gr.Button("‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Memory", size="sm")

        def get_memory_status():
            if RAG_MODE == "enhanced":
                try:
                    memory_info = enhanced_rag.get_memory_info()
                    return f"""üìä Memory Status:
‚Ä¢ Total memories: {memory_info['total_memories']}
‚Ä¢ Session memories: {memory_info['session_memories']}
‚Ä¢ Long-term memories: {memory_info['longterm_memories']}
‚Ä¢ Memory window: {memory_info['memory_window']}
"""
                except Exception as e:
                    return f"Error getting memory status: {str(e)}"
            else:
                return "Enhanced RAG is not active. Switch to Enhanced RAG mode to use memory features."

        refresh_memory_button.click(
            fn=get_memory_status,
            inputs=None,
            outputs=memory_status_output,
            queue=False
        )

        # Chat Bot
        chatbot = gr.Chatbot(type="messages")
        msg = gr.Textbox(label="‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö PDF")
        # Clear button 
        clear_chat = gr.Button("‡∏•‡πâ‡∏≤‡∏á")
        # Submit function 
        msg.submit(
            fn=user,
            inputs=[msg, chatbot],
            outputs=[msg, chatbot],
            queue=False
        ).then(
            fn=chatbot_interface,
            inputs=[chatbot, selected_model, show_source_checkbox, formal_style_checkbox,
                   send_to_discord_checkbox, send_to_line_checkbox, send_to_facebook_checkbox,
                   line_user_id_input, fb_user_id_input],
            outputs=chatbot
        )
        clear_chat.click(lambda: [], None, chatbot, queue=False)

if __name__ == "__main__":
    # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö ‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏£‡∏¥‡πà‡∏° Start Web
    clear_vector_db_and_images()
    demo.launch()